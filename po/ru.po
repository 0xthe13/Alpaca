# Russian translations for Alpaca package.
# Copyright (C) 2024 Jeffry Samuel Eduarte Rojas
# This file is distributed under the same license as the Alpaca package.
# (YOUR NAME) <(EMAIL OPTIONAL)>
#
msgid ""
msgstr ""
"Project-Id-Version: 1.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-06-04 01:32-0600\n"
"PO-Revision-Date: 2024-07-08 17:18+0800\n"
"Last-Translator: (YOUR NAME) <(EMAIL OPTIONAL)>\n"
"Language-Team: Russian\n"
"Language: ru\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"X-Generator: Poedit 3.4.4\n"
"X-Poedit-Basepath: ../src\n"
"X-Poedit-SearchPath-0: .\n"

#: data/com.jeffser.Alpaca.desktop.in:2
#: data/com.jeffser.Alpaca.metainfo.xml.in:7
msgid "Alpaca"
msgstr ""

#: data/com.jeffser.Alpaca.desktop.in:8
msgid "ai;ollama;llm"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:8
msgid "Chat with AI models"
msgstr "Чат с моделями ИИ"

#: data/com.jeffser.Alpaca.metainfo.xml.in:10
msgid "A private AI client"
msgstr "Частный ИИ клиент"

#: data/com.jeffser.Alpaca.metainfo.xml.in:11
#: data/com.jeffser.Alpaca.metainfo.xml.in:1201
msgid "Features"
msgstr "Функции"

#: data/com.jeffser.Alpaca.metainfo.xml.in:13
#: data/com.jeffser.Alpaca.metainfo.xml.in:1203
msgid "Talk to multiple models in the same conversation"
msgstr "Общение с несколькими моделями в одном разговоре"

#: data/com.jeffser.Alpaca.metainfo.xml.in:14
#: data/com.jeffser.Alpaca.metainfo.xml.in:1204
msgid "Pull and delete models from the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:15
msgid "Have multiple conversations"
msgstr "Ведите несколько разговоров"

#: data/com.jeffser.Alpaca.metainfo.xml.in:16
msgid "Image recognition (Only available with compatible models)"
msgstr "Распознавание изображений (доступно только для совместимых моделей)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:17
msgid "Plain text documents recognition"
msgstr "Распознавание текстовых документов"

#: data/com.jeffser.Alpaca.metainfo.xml.in:18
msgid "Import and export chats"
msgstr "Импорт и экспорт чатов"

#: data/com.jeffser.Alpaca.metainfo.xml.in:19
msgid "Append YouTube transcripts to the prompt"
msgstr "Добавление транскриптов YouTube к промпту"

#: data/com.jeffser.Alpaca.metainfo.xml.in:20
msgid "Append text from a website to the prompt"
msgstr "Добавление текста с веб-сайта в промпт"

#: data/com.jeffser.Alpaca.metainfo.xml.in:21
msgid "PDF recognition"
msgstr "Распознавание PDF-файлов"

#: data/com.jeffser.Alpaca.metainfo.xml.in:23 src/window.ui:90
msgid "Disclaimer"
msgstr "Отказ от ответственности"

#: data/com.jeffser.Alpaca.metainfo.xml.in:24
msgid ""
"This project is not affiliated at all with Ollama, I'm not responsible for "
"any damages to your device or software caused by running code given by any "
"models."
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:27
msgid "Jeffry Samuel Eduarte Rojas"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:53
msgid "A normal conversation with an AI Model"
msgstr "Обычный чат с моделью ИИ"

#: data/com.jeffser.Alpaca.metainfo.xml.in:57
msgid "A conversation involving image recognition"
msgstr "Чат, включающий распознавание изображений"

#: data/com.jeffser.Alpaca.metainfo.xml.in:61
msgid "A conversation involving a custom model"
msgstr "Чат с участием пользовательской модели"

#: data/com.jeffser.Alpaca.metainfo.xml.in:65
msgid "A conversation showing code highlighting"
msgstr "Чат с подсветкой кода"

#: data/com.jeffser.Alpaca.metainfo.xml.in:69
msgid "A Python script running inside integrated terminal"
msgstr "Скрипт Python, работающий внутри интегрированного терминала"

#: data/com.jeffser.Alpaca.metainfo.xml.in:73
msgid "A conversation involving a YouTube video transcript"
msgstr "Чат с использованием видеотрансляции YouTube"

#: data/com.jeffser.Alpaca.metainfo.xml.in:77
msgid "Multiple models being downloaded"
msgstr "Могут быть загружены несколько моделей"

#: data/com.jeffser.Alpaca.metainfo.xml.in:81
msgid "Model creator screen"
msgstr "Экран создания модели"

#: data/com.jeffser.Alpaca.metainfo.xml.in:95
#: data/com.jeffser.Alpaca.metainfo.xml.in:109
#: data/com.jeffser.Alpaca.metainfo.xml.in:142
#: data/com.jeffser.Alpaca.metainfo.xml.in:189
#: data/com.jeffser.Alpaca.metainfo.xml.in:236
#: data/com.jeffser.Alpaca.metainfo.xml.in:253
#: data/com.jeffser.Alpaca.metainfo.xml.in:283
#: data/com.jeffser.Alpaca.metainfo.xml.in:293
#: data/com.jeffser.Alpaca.metainfo.xml.in:304
#: data/com.jeffser.Alpaca.metainfo.xml.in:331
#: data/com.jeffser.Alpaca.metainfo.xml.in:351
#: data/com.jeffser.Alpaca.metainfo.xml.in:377
#: data/com.jeffser.Alpaca.metainfo.xml.in:392
#: data/com.jeffser.Alpaca.metainfo.xml.in:417
#: data/com.jeffser.Alpaca.metainfo.xml.in:445
#: data/com.jeffser.Alpaca.metainfo.xml.in:455
#: data/com.jeffser.Alpaca.metainfo.xml.in:466
#: data/com.jeffser.Alpaca.metainfo.xml.in:480
#: data/com.jeffser.Alpaca.metainfo.xml.in:492
#: data/com.jeffser.Alpaca.metainfo.xml.in:508
#: data/com.jeffser.Alpaca.metainfo.xml.in:523
#: data/com.jeffser.Alpaca.metainfo.xml.in:558
#: data/com.jeffser.Alpaca.metainfo.xml.in:583
#: data/com.jeffser.Alpaca.metainfo.xml.in:614
#: data/com.jeffser.Alpaca.metainfo.xml.in:640
#: data/com.jeffser.Alpaca.metainfo.xml.in:662
#: data/com.jeffser.Alpaca.metainfo.xml.in:693
#: data/com.jeffser.Alpaca.metainfo.xml.in:715
#: data/com.jeffser.Alpaca.metainfo.xml.in:736
#: data/com.jeffser.Alpaca.metainfo.xml.in:751
#: data/com.jeffser.Alpaca.metainfo.xml.in:776
msgid "New"
msgstr "Новое"

#: data/com.jeffser.Alpaca.metainfo.xml.in:97
msgid "Multiple QuickAsk window rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:99
#: data/com.jeffser.Alpaca.metainfo.xml.in:120
#: data/com.jeffser.Alpaca.metainfo.xml.in:133
#: data/com.jeffser.Alpaca.metainfo.xml.in:148
#: data/com.jeffser.Alpaca.metainfo.xml.in:157
#: data/com.jeffser.Alpaca.metainfo.xml.in:168
#: data/com.jeffser.Alpaca.metainfo.xml.in:177
#: data/com.jeffser.Alpaca.metainfo.xml.in:225
#: data/com.jeffser.Alpaca.metainfo.xml.in:243
#: data/com.jeffser.Alpaca.metainfo.xml.in:259
#: data/com.jeffser.Alpaca.metainfo.xml.in:271
#: data/com.jeffser.Alpaca.metainfo.xml.in:321
#: data/com.jeffser.Alpaca.metainfo.xml.in:367
#: data/com.jeffser.Alpaca.metainfo.xml.in:398
#: data/com.jeffser.Alpaca.metainfo.xml.in:407
#: data/com.jeffser.Alpaca.metainfo.xml.in:470
#: data/com.jeffser.Alpaca.metainfo.xml.in:498
#: data/com.jeffser.Alpaca.metainfo.xml.in:512
#: data/com.jeffser.Alpaca.metainfo.xml.in:529
#: data/com.jeffser.Alpaca.metainfo.xml.in:540
#: data/com.jeffser.Alpaca.metainfo.xml.in:549
#: data/com.jeffser.Alpaca.metainfo.xml.in:566
#: data/com.jeffser.Alpaca.metainfo.xml.in:576
#: data/com.jeffser.Alpaca.metainfo.xml.in:593
#: data/com.jeffser.Alpaca.metainfo.xml.in:603
#: data/com.jeffser.Alpaca.metainfo.xml.in:650
#: data/com.jeffser.Alpaca.metainfo.xml.in:675
#: data/com.jeffser.Alpaca.metainfo.xml.in:700
#: data/com.jeffser.Alpaca.metainfo.xml.in:722
#: data/com.jeffser.Alpaca.metainfo.xml.in:740
#: data/com.jeffser.Alpaca.metainfo.xml.in:758
#: data/com.jeffser.Alpaca.metainfo.xml.in:770
#: data/com.jeffser.Alpaca.metainfo.xml.in:786
msgid "Fixes"
msgstr "Исправления"

#: data/com.jeffser.Alpaca.metainfo.xml.in:101
msgid "Better stability for QuickAsk"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:102
msgid "Creating a new chat now selects it"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:111
msgid "Chat Search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:112
msgid "Hide \"latest\" and \"custom\" tags from model selector"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:113
msgid "Hide model's languages behind popup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:114
msgid "New models listed for Ollama"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:115
msgid "Added option to autodictate new mesages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:116
msgid "Added Meta Llama API to list of instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:117
msgid ""
"Added new env variables options (\"24H hour formatting\" and \"only Ollama "
"mode\")"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:118
msgid "Made Mermaid scripts executable using Python HTTP server"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:122
msgid "Better stability when switching instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:123
msgid "Better performance when navigating menus"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:124
msgid "Fixed some dialogs not appearing in Quick Ask window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:125
msgid "Faster message search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:126
msgid "Faster message rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:135
msgid "Fixed whisper directory not existing causing error"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:144
#: data/com.jeffser.Alpaca.metainfo.xml.in:993
msgid "Updated model list"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:145
msgid "Alpaca now remembers it's size"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:146
msgid "Added reasoning category for Ollama models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:150
msgid "Improvements in sample prompts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:159
msgid "Fixed auto creation of Ollama (Managed) instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:160
msgid "Removed legacy JSON to SQLite3 migration code"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:161
msgid "Fixed power saving mode appearing whilst using online instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:170
msgid "Fixed Ollama (Manged) instance not being able to be created"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:179
msgid "Instance manager now follows default model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:180
msgid "English text-to-speech voices not working"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:181
msgid "Instance manager sometimes not saving instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:182
msgid "Fixed Gorq and Deepseek instances not generating text"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:191
msgid "Smart tools for models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:192
msgid "Speech recognition (message dictation)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:193 src/widgets/model_manager.py:66
msgid "Text to Speech"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:194
msgid "New Quick Chat system"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:195
msgid "Filter Ollama models by categories"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:196
msgid "Better math Latex rendering in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:197
msgid "Rich text rendering in attachment preview"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:198
msgid "Matplotlib is now included in Python code runner"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:199
msgid "Styling for messages being generated"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:201
#: data/com.jeffser.Alpaca.metainfo.xml.in:309
msgid "New Instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:203
msgid "Deepseek"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:204
msgid "OpenRouter AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:205
msgid "Anthropic"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:206
msgid "Groq Cloud"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:207
msgid "Fireworks AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:208
msgid "Lambda Labs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:210
msgid "New Attachment Types"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:212
msgid "Microsoft Word Document (docx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:213
msgid "Microsoft PowerPoint Document (pptx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:214
msgid "Microsoft Excel Document (xlsx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:216
msgid "New Tools"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:218 src/widgets/tools/tools.py:467
msgid "Run Command (Testing)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:219 src/widgets/tools/tools.py:374
msgid "Online Search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:220 src/widgets/tools/tools.py:332
msgid "Extract Wikipedia Article"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:221 src/widgets/tools/tools.py:214
msgid "Get Recipe by Name"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:222 src/widgets/tools/tools.py:275
msgid "Get Recipes by Category"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:223 src/widgets/tools/tools.py:181
msgid "Get Current Datetime"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:227
msgid "Fixed welcome screen not showing sometimes when deleting a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:228
msgid "Fixed bold text not rendering correctly in tables"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:229
msgid "Fixed sample prompt buttons overflowing on small screens"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:238
msgid "Updated runtime to Gnome 48"
msgstr "Обновлена ​​среда выполнения до Gnome 48"

#: data/com.jeffser.Alpaca.metainfo.xml.in:239
msgid "Added back 'category pills' to model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:240
msgid "Better appearance for model manager sidebar"
msgstr "Лучший внешний вид боковой панели менеджера моделей"

#: data/com.jeffser.Alpaca.metainfo.xml.in:241
#: data/com.jeffser.Alpaca.metainfo.xml.in:257
msgid "New models"
msgstr "Новые модели"

#: data/com.jeffser.Alpaca.metainfo.xml.in:245
msgid "Fixed bad title generation with chain-of-thought models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:246
msgid ""
"Hide page switcher in model manager if there's only one page (online "
"instances)"
msgstr ""
"Скрыть переключатель страниц в менеджере моделей, если есть только одна "
"страница (онлайн-экземпляры"

#: data/com.jeffser.Alpaca.metainfo.xml.in:255
msgid "Option to delete all chats"
msgstr "Возможность удалить все чаты"

#: data/com.jeffser.Alpaca.metainfo.xml.in:256
msgid "Button to refresh sample prompts"
msgstr "Кнопка для обновления примеров промптов"

#: data/com.jeffser.Alpaca.metainfo.xml.in:261
msgid "Fixed saving Ollama (Managed) instance might crash it"
msgstr ""
"Исправлена ​​ошибка, из-за которой сохранение экземпляра Ollama (Работающего) "
"могло привести к его сбою."

#: data/com.jeffser.Alpaca.metainfo.xml.in:262
msgid "Fixed stop button"
msgstr "Исправлена кнопка остановки"

#: data/com.jeffser.Alpaca.metainfo.xml.in:263
msgid "Fixed model search not working if there are only pulling models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:264
msgid "Fixed sample prompts sometimes not appearing"
msgstr ""
"Исправлена ​​ошибка, из-за которой промпты с образцами иногда не отображались."

#: data/com.jeffser.Alpaca.metainfo.xml.in:273
msgid "Don't clear the building output of C++ scripts"
msgstr "Не очищайте выходные данные сборки скриптов C++"

#: data/com.jeffser.Alpaca.metainfo.xml.in:274
msgid "Better handling of attachments"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:275
msgid "Handle remote Ollama instance's API Key better"
msgstr "Лучшая обработка API-ключа удаленного экземпляра Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:276
msgid "Remove '\\n' characters in instance edit page"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:285
msgid "Dynamic chat loading"
msgstr "Динамическая загрузка чата"

#: data/com.jeffser.Alpaca.metainfo.xml.in:286
msgid "Updated Ollama instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:295
msgid "Tweaked appearance of models in model manager"
msgstr "Изменен внешний вид моделей в менеджере моделей."

#: data/com.jeffser.Alpaca.metainfo.xml.in:296
msgid "Updated Ollama instance to 0.5.11"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:297
msgid "Added new models"
msgstr "Добавлены новые модели"

#: data/com.jeffser.Alpaca.metainfo.xml.in:306
msgid "New instance manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:307
msgid "New welcome screen"
msgstr "Новый экрын приветствия"

#: data/com.jeffser.Alpaca.metainfo.xml.in:311
msgid "OpenAI ChatGPT"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:312
msgid "Google Gemini"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:313
msgid "Together AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:314
msgid "Venice"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:323
msgid "Exporting chats with 'thoughts' attachment is fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:324
msgid "Fixed attachment filters"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:333
msgid "New model manager"
msgstr "Новый менеджер моделей"

#: data/com.jeffser.Alpaca.metainfo.xml.in:334
msgid "Changed GtkSpinner to AdwSpinner"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:335
msgid "Better handling of launch process"
msgstr "Лучшая обработка процесса запуска"

#: data/com.jeffser.Alpaca.metainfo.xml.in:336
msgid "New loading screen at launch"
msgstr "Новый загрузочный экран при запуске"

#: data/com.jeffser.Alpaca.metainfo.xml.in:337
msgid "Better handling of file types"
msgstr "Лучшая обработка типов файлов"

#: data/com.jeffser.Alpaca.metainfo.xml.in:338
msgid "Better regex expression for LaTeX equations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:339
msgid "Confirmation dialog if user closes Alpaca whilst a model is downloading"
msgstr ""
"Диалоговое окно подтверждения, если пользователь закрывает Alpaca во время "
"загрузки модели"

#: data/com.jeffser.Alpaca.metainfo.xml.in:340
msgid "Better handling of think tags in messages"
msgstr "Лучшая обработка тегов в сообщениях"

#: data/com.jeffser.Alpaca.metainfo.xml.in:341
msgid "Default model is now in charge of generating titles"
msgstr "Модель по умолчанию теперь отвечает за генерацию заголовков."

#: data/com.jeffser.Alpaca.metainfo.xml.in:342
msgid "Message header is now shown whilst the message is being generated"
msgstr "Заголовок сообщения теперь отображается во время его создания."

#: data/com.jeffser.Alpaca.metainfo.xml.in:343
msgid "Better handling of model profile pictures"
msgstr "Лучшая обработка фотографий профилей моделей"

#: data/com.jeffser.Alpaca.metainfo.xml.in:344
msgid "New models in 'available models' list"
msgstr "Новые модели в списке 'доступных моделей'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:353
msgid "Added option for attaching screenshots"
msgstr "Добавлена ​​возможность прикреплять скриншоты"

#: data/com.jeffser.Alpaca.metainfo.xml.in:354
msgid "Basic LaTeX math equations are now rendered in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:355
msgid "HTML and C++ scripts can now be run inside Alpaca"
msgstr "Скрипты HTML и C++ теперь можно запускать внутри Alpaca"

#: data/com.jeffser.Alpaca.metainfo.xml.in:356
msgid "Added option to open the environment directory from the terminal"
msgstr "Добавлена ​​возможность открыть каталог окружения из терминала."

#: data/com.jeffser.Alpaca.metainfo.xml.in:357
msgid "Added option to edit code blocks directly"
msgstr "Добавлена ​​возможность редактирования блоков кода напрямую."

#: data/com.jeffser.Alpaca.metainfo.xml.in:358
msgid "Complete keyboard shortcut list"
msgstr "Завершен список сочетаний клавиш"

#: data/com.jeffser.Alpaca.metainfo.xml.in:359
msgid "Images are now attached in 640p resolution"
msgstr "Изображения теперь прикрепляются в разрешении 640p."

#: data/com.jeffser.Alpaca.metainfo.xml.in:360
msgid "Website attachments now use extracted titles"
msgstr "Вложения веб-сайта теперь используют извлеченные заголовки"

#: data/com.jeffser.Alpaca.metainfo.xml.in:361
msgid "Better chat title generation"
msgstr "Улучшено создание заголовков чата"

#: data/com.jeffser.Alpaca.metainfo.xml.in:362
msgid "Added option to attach any plain text files"
msgstr "Добавлена ​​возможность прикреплять любые текстовые файлы."

#: data/com.jeffser.Alpaca.metainfo.xml.in:363
msgid "Added spellchecker to message entry"
msgstr "Добавлена ​​проверка орфографии при вводе сообщения"

#: data/com.jeffser.Alpaca.metainfo.xml.in:364
msgid "Alpaca's parameters are now stored using SQLite3"
msgstr "Параметры Alpaca теперь хранятся с использованием SQLite3"

#: data/com.jeffser.Alpaca.metainfo.xml.in:365
msgid "Small appearance changes in text entries"
msgstr "Небольшие изменения внешнего вида текстовых записей"

#: data/com.jeffser.Alpaca.metainfo.xml.in:369
msgid "Alpaca's launch process is more reliable"
msgstr "Процесс запуска Alpaca стал более надежным"

#: data/com.jeffser.Alpaca.metainfo.xml.in:370
msgid "Closing the terminal now kills the script subprocess"
msgstr "Закрытие терминала теперь убивает подпроцесс скрипта."

#: data/com.jeffser.Alpaca.metainfo.xml.in:379
msgid "Transitioned chat backend from JSON to SQLite3"
msgstr "Переведен бэкэнд чата с JSON на SQLite3"

#: data/com.jeffser.Alpaca.metainfo.xml.in:380
msgid "Changed appearance of messages"
msgstr "Изменен внешний вид сообщений"

#: data/com.jeffser.Alpaca.metainfo.xml.in:381
msgid "Added the option to add profile pictures to models"
msgstr "Добавлена ​​возможность добавлять фотографии профилей к моделям."

#: data/com.jeffser.Alpaca.metainfo.xml.in:383
#: data/com.jeffser.Alpaca.metainfo.xml.in:855
#: data/com.jeffser.Alpaca.metainfo.xml.in:904
msgid "Fix"
msgstr "Исправления"

#: data/com.jeffser.Alpaca.metainfo.xml.in:385
msgid "Changed override HIP_VISIBLE_DEVICES to ROCR_VISIBLE_DEVICES"
msgstr "Изменено переопределение HIP_VISIBLE_DEVICES на ROCR_VISIBLE_DEVICES"

#: data/com.jeffser.Alpaca.metainfo.xml.in:394
msgid "Added categories to models"
msgstr "Добавлены категории моделей"

#: data/com.jeffser.Alpaca.metainfo.xml.in:395
msgid "Specified model's languages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:396
msgid "Added warning when downloading embedding models"
msgstr "Добавлено предупреждение при загрузке встраиваемых моделей"

#: data/com.jeffser.Alpaca.metainfo.xml.in:400
msgid "Replaced low ram warning with big model warning"
msgstr ""
"Предупреждение о низком объёме оперативной памяти заменено на предупреждение "
"о большой обьёме модели"

#: data/com.jeffser.Alpaca.metainfo.xml.in:409
msgid "Correctly escape markup before rendering message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:410
msgid "Fixed about dialog not working if log file was missing"
msgstr ""
"Исправлена ошибка, из-за которой диалоговое окно не работало, если "
"отсутствовал файл журнала"

#: data/com.jeffser.Alpaca.metainfo.xml.in:419
msgid "System messages can now be sent directly from Alpaca"
msgstr "Системные сообщения теперь можно отправлять непосредственно из Alpaca"

#: data/com.jeffser.Alpaca.metainfo.xml.in:420
msgid "New redesign for messages and smaller minimum size"
msgstr "Новый редизайн сообщений и меньший минимальный размер"

#: data/com.jeffser.Alpaca.metainfo.xml.in:421
msgid "New models included in 'available models list'"
msgstr "Новые модели, включены в список 'доступных моделей'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:422
msgid "Added symbolic icon when attaching code files"
msgstr "Добавлен символический значок при прикреплении файлов кода"

#: data/com.jeffser.Alpaca.metainfo.xml.in:423
msgid "When exporting a chat it now includes a markdown file"
msgstr "При экспорте чата теперь он включает в себя файл markdown (.md)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:424
msgid "Refresh button in model manager when using a remote instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:425
msgid "Assistant messages are now editable"
msgstr "Сообщения помощника теперь доступны для редактирования"

#: data/com.jeffser.Alpaca.metainfo.xml.in:426
msgid "Updated Ollama to v0.5.2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:427
msgid "New option to change model directory"
msgstr "Новая возможность изменить каталог моделей"

#: data/com.jeffser.Alpaca.metainfo.xml.in:428
msgid "File previewer now resizes dynamically to content"
msgstr ""
"Программа предварительного просмотра файлов теперь динамически изменяет "
"размер в соответствии с содержимым"

#: data/com.jeffser.Alpaca.metainfo.xml.in:429
msgid "Adapted Alpaca to work without integrated Ollama instance"
msgstr "Alpaca адаптирован для работы без встроенного экземпляра Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:430
msgid "Compatibility added with ODT files"
msgstr "Добавлена ​​совместимость с файлами ODT"

#: data/com.jeffser.Alpaca.metainfo.xml.in:433
msgid "Restored ROCm compatibility"
msgstr "Восстановлена совместимость с ROCm"

#: data/com.jeffser.Alpaca.metainfo.xml.in:434
msgid ""
"Added long press gesture to chat rows so actions can be done in touchscreens"
msgstr ""
"Добавлен жест длительного нажатия в строках чата, чтобы действия можно было "
"выполнять на сенсорных экранах"

#: data/com.jeffser.Alpaca.metainfo.xml.in:435
msgid "Fixed edit button not saving changes"
msgstr ""
"Исправлена ошибка, при которой кнопка редактирования не сохраняла изменения"

#: data/com.jeffser.Alpaca.metainfo.xml.in:436
msgid "Changed max temperature value to 2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:437
msgid "Made seed 0 actually random"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:438
msgid ""
"Fixed Gnome search provider not working outside of Flatpak installations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:447
msgid "New option --ask MESSAGE, to open a new 'Quick Ask' window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:448
msgid "Gnome Search integration now works whilst the app is opened"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:457
msgid ""
"Added launch paramenters --ask MESSAGE, --new-chat CHAT, --select-chat CHAT, "
"--list-chats, --version"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:458
msgid "Added integration as Gnome Search Provider"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:459
msgid "Updated Ollama to v0.4.2 with new models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:468
msgid "User messages are now compacted into bubbles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:472
msgid ""
"Fixed re connection dialog not working when 'use local instance' is selected"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:473
msgid "Fixed model manager not adapting to large system fonts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:482
msgid "Details page for models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:483
msgid ""
"Model selector gets replaced with 'manage models' button when there are no "
"models downloaded"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:484
msgid "Added warning when model is too big for the device"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:485
msgid "Added AMD GPU indicator in preferences"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:494
msgid "Better system for handling dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:495
msgid "Better system for handling instance switching"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:496
msgid "Remote connection dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:500
msgid "Fixed: Models get duplicated when switching remote and local instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:501
msgid "Better internal instance manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:510
msgid "Added 'Cancel' and 'Save' buttons when editing a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:514
msgid "Better handling of image recognition"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:515
msgid "Remove unused files when canceling a model download"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:516
msgid "Better message blocks rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:525
msgid "Run bash and python scripts straight from chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:526
msgid "Updated Ollama to 0.3.12"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:527
msgid "New models!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:531
msgid "Fixed and made faster the launch sequence"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:532
msgid "Better detection of code blocks in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:533
msgid "Fixed app not loading in certain setups with Nvidia GPUs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:542
msgid ""
"Fixed message notification sometimes crashing text rendering because of them "
"running on different threads"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:551
msgid "Fixed message generation sometimes failing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:560
msgid "Sidebar resizes with the window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:561
msgid "New welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:562
msgid "Message search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:563
msgid "Updated Ollama to v0.3.11"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:564
msgid "A lot of new models provided by Ollama repository"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:568
msgid ""
"Fixed text inside model manager when the accessibility option 'large text' "
"is on"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:569
msgid "Fixed image recognition on unsupported models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:578
msgid "Fixed spinner not hiding if the back end fails"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:579
msgid "Fixed image recognition with local images"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:580
msgid "Changed appearance of delete / stop model buttons"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:581
msgid "Fixed stop button crashing the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:585
msgid "Made sidebar resize a little when the window is smaller"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:586
msgid "Instant launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:595
msgid "Fixed error on first run (welcome dialog)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:596
msgid "Fixed checker for Ollama instance (used on system packages)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:605
msgid "Fixed 'clear chat' option"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:606
msgid "Fixed welcome dialog causing the local instance to not launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:607
msgid "Fixed support for AMD GPUs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:616
msgid "Model, message and chat systems have been rewritten"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:617
msgid "New models are available"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:618
msgid "Ollama updated to v0.3.9"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:619
msgid "Added support for multiple chat generations simultaneously"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:620
msgid "Added experimental AMD GPU support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:621
msgid "Added message loading spinner and new message indicator to chat tab"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:622
msgid "Added animations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:623
msgid "Changed model manager / model selector appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:624
msgid "Changed message appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:625
msgid "Added markdown and code blocks to user messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:626
msgid "Added loading dialog at launch so the app opens faster"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:627
msgid "Added warning when device is on 'battery saver' mode"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:628
msgid "Added inactivity timer to integrated instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:631
msgid "The chat is now scrolled to the bottom when it's changed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:632
msgid "Better handling of focus on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:633
msgid "Better general performance on the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:642
msgid "New duplicate chat option"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:643
msgid "Changed model selector appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:644
msgid "Message entry is focused on launch and chat change"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:645
msgid "Message is focused when it's being edited"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:646
msgid "Added loading spinner when regenerating a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:647
msgid "Added Ollama debugging to 'About Alpaca' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:648
msgid "Changed YouTube transcription dialog appearance and behavior"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:652
msgid "CTRL+W and CTRL+Q stops local instance before closing the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:653
msgid "Changed appearance of 'Open Model Manager' button on welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:654
msgid "Fixed message generation not working consistently"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:655
msgid "Fixed message edition not working consistently"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:664
msgid "Model manager opens faster"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:665
msgid "Delete chat option in secondary menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:666
msgid "New model selector popup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:667
msgid "Standard shortcuts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:668
msgid "Model manager is navigable with keyboard"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:669
msgid "Changed sidebar collapsing behavior"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:670
msgid "Focus indicators on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:671
msgid "Welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:672
msgid "Give message entry focus at launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:673
msgid "Generally better code"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:677
msgid "Better width for dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:678
msgid "Better compatibility with screen readers"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:679
msgid "Fixed message regenerator"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:680
msgid "Removed 'Featured models' from welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:681
msgid "Added default buttons to dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:682
msgid "Fixed import / export of chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:683
msgid "Changed Python2 title to Python on code blocks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:684
msgid ""
"Prevent regeneration of title when the user changed it to a custom title"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:685
msgid "Show date on stopped messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:686
msgid "Fix clear chat error"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:695
msgid "Changed shortcuts to standards"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:696
msgid "Moved 'Manage Models' button to primary menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:697
#: data/com.jeffser.Alpaca.metainfo.xml.in:719
msgid "Stable support for GGUF model files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:698
#: data/com.jeffser.Alpaca.metainfo.xml.in:973
msgid "General optimizations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:702
msgid "Better handling of enter key (important for Japanese input)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:703
msgid "Removed sponsor dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:704
msgid "Added sponsor link in about dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:705
msgid "Changed window and elements dimensions"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:706
msgid "Selected model changes when entering model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:707
msgid "Better image tooltips"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:708
msgid "GGUF Support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:717
msgid "Regenerate any response, even if they are incomplete"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:718
msgid "Support for pulling models by name:tag"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:720
msgid "Restored sidebar toggle button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:724
msgid "Reverted back to standard styles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:725
msgid "Fixed generated titles having \"'S\" for some reason"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:726
msgid "Changed min width for model dropdown"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:727
msgid "Changed message entry shadow"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:728
msgid "The last model used is now restored when the user changes chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:729
msgid "Better check for message finishing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:738
msgid "Added table rendering (Thanks Nokse)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:742
msgid "Made support dialog more common"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:743
msgid ""
"Dialog title on tag chooser when downloading models didn't display properly"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:744
msgid "Prevent chat generation from generating a title with multiple lines"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:753
msgid "Bearer Token entry on connection error dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:754
msgid "Small appearance changes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:755
msgid "Compatibility with code blocks without explicit language"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:756
msgid "Rare, optional and dismissible support dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:760
msgid "Date format for Simplified Chinese translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:761
msgid "Bug with unsupported localizations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:762
msgid "Min height being too large to be used on mobile"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:763
msgid "Remote connection checker bug"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:772
msgid "Models with capital letters on their tag don't work"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:773
msgid "Ollama fails to launch on some systems"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:774
msgid "YouTube transcripts are not being saved in the right TMP directory"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:778
msgid "Debug messages are now shown on the 'About Alpaca' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:779
msgid "Updated Ollama to v0.3.0 (new models)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:788
msgid "Models with '-' in their names didn't work properly, this is now fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:789
msgid "Better connection check for Ollama"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:796
msgid "Stable Release"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:797
msgid ""
"The new icon was made by Tobias Bernard over the Gnome Gitlab, thanks for "
"the great icon!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:798
msgid "Features and fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:800
msgid "Updated Ollama instance to 0.2.8"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:801
msgid "Better model selector"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:802
msgid "Model manager redesign"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:803
msgid "Better tag selector when pulling a model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:804
msgid "Model search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:805
msgid "Added support for bearer tokens on remote instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:806
msgid "Preferences dialog redesign"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:807
msgid "Added context menus to interact with a chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:808
msgid "Redesigned primary and secondary menus"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:809
msgid ""
"YouTube integration: Paste the URL of a video with a transcript and it will "
"be added to the prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:810
msgid ""
"Website integration (Experimental): Extract the text from the body of a "
"website by adding it's URL to the prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:811
msgid "Chat title generation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:812
msgid "Auto resizing of message entry"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:813
msgid "Chat notifications"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:814
msgid "Added indicator when an image is missing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:815
msgid "Auto rearrange the order of chats when a message is received"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:816
msgid "Redesigned file preview dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:817
msgid "Credited new contributors"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:818
msgid "Better stability and optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:819
msgid "Edit messages to change the context of a conversation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:820
msgid "Added disclaimers when pulling models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:821
msgid "Preview files before sending a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:822
msgid "Better format for date and time on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:823
msgid "Error and debug logging on terminal"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:824
msgid "Auto-hiding sidebar button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:825
msgid "Various UI tweaks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:827
msgid "New Models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:829
msgid "Gemma2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:830
msgid "GLM4"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:831
msgid "Codegeex4"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:832
msgid "InternLM2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:833
msgid "Llama3-groq-tool-use"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:834
msgid "Mathstral"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:835
msgid "Mistral-nemo"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:836
msgid "Firefunction-v2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:837
msgid "Nuextract"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:839
msgid "Translations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:840
msgid ""
"These are all the available translations on 1.0.0, thanks to all the "
"contributors!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:842
msgid "Russian: Alex K"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:843
msgid "Spanish: Jeffser"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:844
msgid "Brazilian Portuguese: Daimar Stein"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:845
msgid "French: Louis Chauvet-Villaret"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:846
msgid "Norwegian: CounterFlow64"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:847
msgid "Bengali: Aritra Saha"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:848
msgid "Simplified Chinese: Yuehao Sui"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:856
msgid ""
"Removed DOCX compatibility temporally due to error with python-lxml "
"dependency"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:862
#: data/com.jeffser.Alpaca.metainfo.xml.in:892
#: data/com.jeffser.Alpaca.metainfo.xml.in:913
#: data/com.jeffser.Alpaca.metainfo.xml.in:1118
#: data/com.jeffser.Alpaca.metainfo.xml.in:1175
msgid "Big Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:864
msgid "Added compatibility for PDF"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:865
msgid "Added compatibility for DOCX"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:866
msgid "Merged 'file attachment' menu into one button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:873
#: data/com.jeffser.Alpaca.metainfo.xml.in:1066
msgid "Quick Fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:874
msgid ""
"There were some errors when transitioning from the old version of chats to "
"the new version. I apologize if this caused any corruption in your chat "
"history. This should be the only time such a transition is needed."
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:880
#: data/com.jeffser.Alpaca.metainfo.xml.in:1032
msgid "Huge Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:882
msgid "Added: Support for plain text files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:883
msgid "Added: New backend system for storing messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:884
msgid "Added: Support for changing Ollama's overrides"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:885
msgid "General Optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:894
msgid "Added: Support for GGUF models (experimental)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:895
msgid "Added: Support for customization and creation of models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:896
msgid "Fixed: Icons don't appear on non Gnome systems"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:897
msgid "Update Ollama to v0.1.39"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:906
msgid ""
"Fixed: app didn't open if models tweaks wasn't present in the config files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:915
msgid "Changed multiple icons (paper airplane for the send button)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:916
msgid "Combined export / import chat buttons into a menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:917
msgid "Added 'model tweaks' (temperature, seed, keep_alive)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:918
msgid "Fixed send / stop button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:919
msgid "Fixed app not checking if remote connection works when starting"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:926
msgid "Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:928
msgid "Added text ellipsis to chat name so it doesn't change the button width"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:929
msgid "New shortcut for creating a chat (CTRL+N)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:930
msgid "New message entry design"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:931
msgid "Fixed: Can't rename the same chat multiple times"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:938
msgid "The fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:940
msgid ""
"Fixed: Ollama instance keeps running on the background even when it is "
"disabled"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:941
msgid "Fixed: Can't pull models on the integrated instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:948
msgid "Quick tweaks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:950
msgid "Added progress bar to models that are being pulled"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:951
msgid "Added size to tags when pulling a model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:952
msgid "General optimizations on the background"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:959
msgid "Quick fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:961
msgid "Fixed: Scroll when message is received"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:962
msgid "Fixed: Content doesn't change when creating a new chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:963
msgid "Added 'Featured Models' page on welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:970
msgid "Nice Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:972
msgid "UI tweaks (Thanks Nokse22)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:974
msgid "Metadata fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:981
msgid "Quick fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:983
msgid "Updated Spanish translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:984
msgid "Added compatibility for PNG"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:991
msgid "New Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:994
msgid "Added image recognition to more models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:995
msgid "Added Brazilian Portuguese translation (Thanks Daimaar Stein)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:996
msgid "Refined the general UI (Thanks Nokse22)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:997
msgid "Added 'delete message' feature"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:998
msgid ""
"Added metadata so that software distributors know that the app is compatible "
"with mobile"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:999
msgid ""
"Changed 'send' shortcut to just the return/enter key (to add a new line use "
"shift+return)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1006
msgid "Bug Fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1008
msgid "Fixed: Minor spelling mistake"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1009
msgid "Added 'mobile' as a supported form factor"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1010
msgid "Fixed: 'Connection Error' dialog not working properly"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1011
msgid "Fixed: App might freeze randomly on startup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1012
msgid "Changed 'chats' label on sidebar for 'Alpaca'"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1019
msgid "Cool Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1021
msgid "Better design for chat window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1022
msgid "Better design for chat sidebar"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1023
msgid "Fixed remote connections"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1024
msgid "Fixed Ollama restarting in loop"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1025
msgid "Other cool backend stuff"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1034
msgid "Added Ollama as part of Alpaca, Ollama will run in a sandbox"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1035
msgid "Added option to connect to remote instances (how it worked before)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1036
msgid "Added option to import and export chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1037
msgid "Added option to run Alpaca with Ollama in the background"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1038
msgid "Added preferences dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1039
msgid "Changed the welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1041
#: data/com.jeffser.Alpaca.metainfo.xml.in:1058
#: data/com.jeffser.Alpaca.metainfo.xml.in:1070
#: data/com.jeffser.Alpaca.metainfo.xml.in:1089
#: data/com.jeffser.Alpaca.metainfo.xml.in:1110
#: data/com.jeffser.Alpaca.metainfo.xml.in:1126
#: data/com.jeffser.Alpaca.metainfo.xml.in:1142
#: data/com.jeffser.Alpaca.metainfo.xml.in:1156
#: data/com.jeffser.Alpaca.metainfo.xml.in:1166
#: data/com.jeffser.Alpaca.metainfo.xml.in:1184
#: data/com.jeffser.Alpaca.metainfo.xml.in:1206
msgid "Please report any errors to the issues page, thank you."
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1049
msgid "Yet Another Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1051
msgid "Added better UI for 'Manage Models' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1052
msgid "Added better UI for the chat sidebar"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1053
msgid ""
"Replaced model description with a button to open Ollama's website for the "
"model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1054
msgid "Added myself to the credits as the spanish translator"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1055
msgid "Using XDG properly to get config folder"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1056
msgid "Update for translations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1068
msgid "The last update had some mistakes in the description of the update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1078
msgid "Another Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1080
msgid "Added full Spanish translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1081
msgid "Added support for background pulling of multiple models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1082
msgid "Added interrupt button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1083
msgid "Added basic shortcuts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1084
msgid "Better translation support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1085
msgid ""
"User can now leave chat name empty when creating a new one, it will add a "
"placeholder name"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1086
msgid "Better scalling for different window sizes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1087
msgid "Fixed: Can't close app if first time setup fails"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1097
msgid "Really Big Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1099
msgid "Added multiple chats support!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1100
msgid "Added Pango Markup support (bold, list, title, subtitle, monospace)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1101
msgid "Added autoscroll if the user is at the bottom of the chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1102
msgid "Added support for multiple tags on a single model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1103
msgid "Added better model management dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1104
msgid "Added loading spinner when sending message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1105
msgid "Added notifications if app is not active and a model pull finishes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1106
msgid "Added new symbolic icon"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1107
msgid "Added frame to message textview widget"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1108
msgid "Fixed \"code blocks shouldn't be editable\""
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1120
msgid "Added code highlighting"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1121
msgid "Added image recognition (llava model)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1122
msgid "Added multiline prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1123
msgid "Fixed some small bugs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1124
msgid "General optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1134
msgid "Fixes and features"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1136
msgid "Russian translation (thanks github/alexkdeveloper)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1137
msgid "Fixed: Cannot close app on first setup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1138
msgid "Fixed: Brand colors for Flathub"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1139
msgid "Fixed: App description"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1140
msgid "Fixed: Only show 'save changes dialog' when you actually change the url"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1150
msgid "0.2.2 Bug fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1152
msgid "Toast messages appearing behind dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1153
msgid "Local model list not updating when changing servers"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1154
msgid "Closing the setup dialog closes the whole app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1164
msgid "0.2.1 Data saving fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1165
msgid ""
"The app didn't save the config files and chat history to the right "
"directory, this is now fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1174
msgid "0.2.0"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1176
msgid "New Features"
msgstr "Новые функции"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1178
msgid "Restore chat after closing the app"
msgstr "Восстановить чат после закрытия приложения"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1179
msgid "A button to clear the chat"
msgstr "Кнопка очистки чата"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1180
msgid "Fixed multiple bugs involving how messages are shown"
msgstr "Исправлены многочисленные ошибки, связанные с отображением сообщений"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1181
msgid "Added welcome dialog"
msgstr "Добавлен диалог приветствия"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1182
msgid "More stability"
msgstr "Увеличена стабильность"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1192
msgid "0.1.2 Quick fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1193
msgid ""
"This release fixes some metadata needed to have a proper Flatpak application"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1199
msgid "0.1.1 Stable Release"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1200
msgid "This is the first public version of Alpaca"
msgstr "Это первая общедоступная версия Alpaca"

#: src/alpaca_search_provider.py.in:41
msgid "Open chat"
msgstr "Открыть чат"

#: src/alpaca_search_provider.py.in:42
msgid "Quick ask"
msgstr ""

#: src/constants.py:95
msgid "Never"
msgstr ""

#: src/constants.py:96
msgid "When Alpaca is Focused"
msgstr ""

#: src/constants.py:97
msgid "Always"
msgstr ""

#: src/main.py:204
msgid "Documentation"
msgstr ""

#: src/main.py:205
msgid "Become a Sponsor"
msgstr ""

#: src/main.py:206
msgid "Discussions"
msgstr ""

#: src/ollama_models.py:33
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to the Llama 3.1 405B model."
msgstr ""

#: src/ollama_models.py:56
msgid "QwQ is the reasoning model of the Qwen series."
msgstr ""

#: src/ollama_models.py:84
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""

#: src/ollama_models.py:120
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr ""

#: src/ollama_models.py:155
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr ""

#: src/ollama_models.py:182
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3: Самый мощный из открытых LLM на сегодняшний день"

#: src/ollama_models.py:205
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr "Модель 7Б, выпущенная Mistral AI, обновлена ​​до версии 0.3."

#: src/ollama_models.py:229
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr ""
"Высокопроизводительная открытая модель внедрения с большим окном контекста "
"токена."

#: src/ollama_models.py:258
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr ""
"Gemma — это семейство легких современных открытых моделей, созданных Google "
"DeepMind. Обновлено до версии 1.1"

#: src/ollama_models.py:314
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr ""
"Qwen 1.5 — это серия крупных языковых моделей от Alibaba Cloud с параметрами "
"от 0,5 до 110 B"

#: src/ollama_models.py:378
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr "Qwen2 — новая серия больших языковых моделей от группы Alibaba"

#: src/ollama_models.py:407
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 — это семейство легких современных открытых моделей 3B (Mini) и 14B "
"(Medium) от Microsoft."

#: src/ollama_models.py:439
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr ""
"Llama 2 — это набор базовых языковых моделей с параметрами от 7B до 70B."

#: src/ollama_models.py:501
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""

#: src/ollama_models.py:533
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr ""

#: src/ollama_models.py:567
msgid ""
"🌋 LLaVA is a novel end-to-end trained large multimodal model that combines "
"a vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"🌋 LLaVA — это новая комплексная обученная большая мультимодальная модель, "
"которая сочетает в себе видеокодер и Vicuna для общего визуального и "
"языкового понимания. Обновлено до версии 1.6."

#: src/ollama_models.py:604
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr ""
"Большая языковая модель, которая может использовать текстовые подсказки для "
"создания и обсуждения кода."

#: src/ollama_models.py:650
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""

#: src/ollama_models.py:674
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr ""

#: src/ollama_models.py:696
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"Проект TinyLlama — это открытая попытка обучить компактную модель Llama "
"размером 1,1B на 3 триллионах токенов."

#: src/ollama_models.py:719
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "Современная большая модель встраивания от mixbread.ai"

#: src/ollama_models.py:752
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 — это следующее поколение LLM с прозрачным обученным открытым "
"кодом, которое поставляется в трех размерах: параметры 3B, 7B и 15B."

#: src/ollama_models.py:778
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"Набор модели Mixture of Experts (MoE) с открытыми весами от Mistral AI с "
"размерами параметров 8x7b и 8x22b."

#: src/ollama_models.py:804
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"Без цензуры, точно настроенные модели 8x7b и 8x22b, основанные на смеси "
"экспертных моделей Mixtral, которые превосходно справляются с задачами "
"кодирования. Создан Эриком Хартфордом."

#: src/ollama_models.py:833
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma — это набор мощных и легких моделей, которые могут выполнять "
"различные задачи кодирования, такие как завершение кода с заполнением "
"посередине, генерация кода, понимание естественного языка, математические "
"рассуждения и выполнение инструкций."

#: src/ollama_models.py:861
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"Модель языка кода Mixture-of-Experts с открытым исходным кодом, "
"обеспечивающая производительность, сравнимую с GPT4-Turbo, в задачах, "
"специфичных для кода."

#: src/ollama_models.py:883
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr ""
"Phi-2: языковая модель 2,7B от Microsoft Research, демонстрирующая "
"выдающиеся способности к рассуждению и пониманию языка."

#: src/ollama_models.py:910
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "Модель Llama 2 без цензуры от Джорджа Санга и Джаррада Хоупа."

#: src/ollama_models.py:945
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder — это эффективная модель кодирования, обученная на двух "
"триллионах кода и токенах естественного языка."

#: src/ollama_models.py:986
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr ""
"Набор моделей встраивания текста от Snowflake, оптимизированных для "
"повышения производительности."

#: src/ollama_models.py:1014
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"Современная модель большого языка от Microsoft AI с улучшенной "
"производительностью в сложных чатах, многоязычных средах, рассуждениях и "
"сценариях использования агентов."

#: src/ollama_models.py:1037
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr ""
"Модель Dolphin без цензуры, основанная на Mistral, которая превосходно "
"справляется с задачами кодирования. Обновлено до версии 2.8."

#: src/ollama_models.py:1065
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9 — это новая модель размеров 8B и 70B, созданная Эриком "
"Хартфордом на основе Llama 3, которая обладает разнообразными навыками "
"обучения, общения и программирования."

#: src/ollama_models.py:1099
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 — это высокопроизводительная двуязычная языковая модель."

#: src/ollama_models.py:1122
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr ""
"Command R — это большая языковая модель, оптимизированная для диалогового "
"взаимодействия и задач с длинным контекстом."

#: src/ollama_models.py:1159
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr ""
"Модель общего назначения с числом параметров от 3 до 70 миллиардов, "
"подходящая для аппаратного обеспечения начального уровня."

#: src/ollama_models.py:1182
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr ""
"Модель LLaVA, доработанная на основе Llama 3 Instruct, с лучшими "
"показателями в нескольких тестах."

#: src/ollama_models.py:1209
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr — это серия доработанных версий моделей Mistral и Mixtral, которые "
"обучены выполнять роль полезных помощников."

#: src/ollama_models.py:1231
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr ""

#: src/ollama_models.py:1259
msgid "Embedding models on very large sentence level datasets."
msgstr ""
"Встраивание моделей в очень большие наборы данных на уровне предложений."

#: src/ollama_models.py:1282
msgid ""
"Codestral is Mistral AI’s first-ever code model designed for code generation "
"tasks."
msgstr ""
"Codestral — это первая модель кода Mistral AI, предназначенная для задач "
"генерации кода."

#: src/ollama_models.py:1319
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr ""
"StarCoder — это модель генерации кода, обученная на более чем 80 языках "
"программирования."

#: src/ollama_models.py:1351
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr ""
"Модель чата общего использования на основе Llama и Llama 2 с размерами "
"контекста от 2 до 16 КБ."

#: src/ollama_models.py:1388
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr "Семейство моделей открытого фонда от IBM для Code Intelligence"

#: src/ollama_models.py:1410
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca — это модель с 7 миллиардами параметров, доработанная на "
"основе модели Mistral 7B с использованием набора данных OpenOrca."

#: src/ollama_models.py:1442
msgid ""
"🪐 A family of small models with 135M, 360M, and 1.7B parameters, trained on "
"a new high-quality dataset."
msgstr ""

#: src/ollama_models.py:1474
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored — это модель с параметрами 7B, 13B и 30B, "
"основанная на Llama 2 без цензуры Эрика Хартфорда."

#: src/ollama_models.py:1503
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr ""
"Модель на основе Llama 2 настроена для улучшения навыков диалога на "
"китайском языке."

#: src/ollama_models.py:1526
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr ""

#: src/ollama_models.py:1551
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr ""

#: src/ollama_models.py:1574
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"Семейство моделей с открытым исходным кодом, обученных на широком спектре "
"данных, превосходящих ChatGPT по различным критериям. Обновлено до версии "
"3.5-0106."

#: src/ollama_models.py:1602
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr ""
"Aya 23, выпущенная компанией Cohere, представляет собой новое семейство "
"современных многоязычных моделей, поддерживающих 23 языка."

#: src/ollama_models.py:1625
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr ""
"CodeQwen1.5 — это большая языковая модель, предварительно обученная на "
"большом объеме данных кода."

#: src/ollama_models.py:1653
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr ""
"Мощное семейство моделей от Nous Research, которое превосходно справляется с "
"задачами научного обсуждения и кодирования."

#: src/ollama_models.py:1675
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+ — это мощная масштабируемая модель большого языка, специально "
"созданная для достижения успеха в реальных корпоративных сценариях "
"использования."

#: src/ollama_models.py:1698
msgid "State-of-the-art code generation model"
msgstr "Современная модель генерации кода"

#: src/ollama_models.py:1722
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"Стабильный код 3B — это модель кодирования с вариантами инструкций и "
"завершения кода наравне с такими моделями, как Code Llama 7B, которые в 2,5 "
"раза больше."

#: src/ollama_models.py:1744
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"Экспериментальная модель с параметрами 1.1B, обученная на новом наборе "
"данных Dolphin 2.8 Эрика Хартфорда и основанная на TinyLlama."

#: src/ollama_models.py:1771
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5 — это модель 7B, доработанная Teknium на Mistral с полностью "
"открытыми наборами данных."

#: src/ollama_models.py:1795
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""

#: src/ollama_models.py:1828
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""

#: src/ollama_models.py:1852
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr ""

#: src/ollama_models.py:1886
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"Stable LM 2 — это современная языковая модель с параметрами 1,6B и 12B, "
"обученная на многоязычных данных на английском, испанском, немецком, "
"итальянском, французском, португальском и голландском языках."

#: src/ollama_models.py:1909
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr ""
"BakLLaVA — мультимодальная модель, состоящая из базовой модели Mistral 7B, "
"дополненной архитектурой LLaVA."

#: src/ollama_models.py:1930
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""

#: src/ollama_models.py:1961
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr ""
"Усовершенствованная языковая модель, созданная на основе 2 триллионов "
"двуязычных токенов."

#: src/ollama_models.py:1988
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr ""
"Эта модель увеличивает длину контекста LLama-3 8B с 8 тыс. до более чем 1 "
"млн токенов."

#: src/ollama_models.py:2021
msgid "Model focused on math and logic problems"
msgstr "Модель ориентирована на математические и логические задачи"

#: src/ollama_models.py:2044
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr ""
"moondream2 — это небольшая языковая модель видения, предназначенная для "
"эффективной работы на периферийных устройствах."

#: src/ollama_models.py:2066
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr ""
"Доработанная модель на базе Mistral с хорошим охватом предметной области и "
"языка."

#: src/ollama_models.py:2093
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"Модель от NVIDIA на основе Llama 3, которая превосходно справляется с "
"диалоговым ответом на вопросы (QA) и генерацией с расширенным поиском (RAG)."

#: src/ollama_models.py:2120
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr ""
"Диалоговая модель на базе Llama 2, конкурентоспособная по различным "
"показателям."

#: src/ollama_models.py:2148
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr ""
"SQLCoder — это модель завершения кода, настроенная в StarCoder для задач "
"генерации SQL"

#: src/ollama_models.py:2175
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr "Модели общего пользования на базе Llama и Llama 2 от Nous Research."

#: src/ollama_models.py:2198
msgid "Code generation model based on Code Llama."
msgstr "Модель генерации кода на основе Code Llama."

#: src/ollama_models.py:2225
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr "Расширение Llama 2, поддерживающее контекст до 128 тыс. токенов."

#: src/ollama_models.py:2253
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr ""
"Вариант семейства моделей Dolphin 7B и 15B без цензуры, превосходный в "
"кодировании, на основе StarCoder2."

#: src/ollama_models.py:2280
msgid "General use model based on Llama 2."
msgstr "Модель общего назначения на базе Llama 2."

#: src/ollama_models.py:2309
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr "Сильная, экономичная и эффективная языковая модель «Смесь экспертов»."

#: src/ollama_models.py:2331
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling — это большая языковая модель, обученная с помощью обучения с "
"подкреплением на основе отзывов искусственного интеллекта, направленная на "
"повышение полезности чат-бота."

#: src/ollama_models.py:2353
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr ""
"Помощник-компаньон, прошедший обучение в области философии, психологии и "
"личных отношений. На базе Мистраля."

#: src/ollama_models.py:2391
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr ""

#: src/ollama_models.py:2419
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""

#: src/ollama_models.py:2450
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""

#: src/ollama_models.py:2487
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr ""

#: src/ollama_models.py:2509
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr ""
"Компактная, но мощная языковая модель с поддержкой 10,7 ББ, предназначенная "
"для одноразового разговора."

#: src/ollama_models.py:2533
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""

#: src/ollama_models.py:2556
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr "Новая маленькая модель LLaVA, доработанная на основе Phi 3 Mini."

#: src/ollama_models.py:2584
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"Orca 2 создана в результате исследований Microsoft и представляет собой "
"доработанную версию моделей Meta 2 Llama 2. Модель разработана, чтобы "
"преуспеть, в частности, в рассуждениях."

#: src/ollama_models.py:2615
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr ""

#: src/ollama_models.py:2647
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"Модель на основе Llama 2 точно настроена на наборе данных в стиле Orca. "
"Первоначально назывался Свободный Вилли."

#: src/ollama_models.py:2676
msgid ""
"Mistral Small 3 sets a new benchmark in the “small” Large Language Models "
"category below 70B."
msgstr ""

#: src/ollama_models.py:2698
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"2.7B модель Dolphin без цензуры Эрика Хартфорда, основанная на модели языка "
"Phi, разработанной Microsoft Research."

#: src/ollama_models.py:2731
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""

#: src/ollama_models.py:2753
msgid "Uncensored version of Wizard LM model"
msgstr "Версия модели Wizard LM без цензуры"

#: src/ollama_models.py:2776
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""

#: src/ollama_models.py:2798
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr ""
"Расширение Mistral для поддержки контекстных окон размером 64 КБ или 128 КБ."

#: src/ollama_models.py:2826
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"Расширение Llama 2, которое специализируется на интеграции как общего "
"понимания языка, так и знаний по конкретной предметной области, особенно в "
"области программирования и математики."

#: src/ollama_models.py:2848
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr ""
"Точная настройка модели Llama 2 для ответа на медицинские вопросы на основе "
"набора медицинских данных с открытым исходным кодом."

#: src/ollama_models.py:2875
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr ""
"Большая языковая модель  с открытым исходным кодом, адаптированная из Llama "
"2 для медицинской сферы."

#: src/ollama_models.py:2903
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""

#: src/ollama_models.py:2925
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""

#: src/ollama_models.py:2947
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr ""
"Nexus Raven — это модель с поддержкой 13B инструкций для задач вызова "
"функций."

#: src/ollama_models.py:2968
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr ""
"Модель Nous Hermes 2 от Nous Research, которая теперь обучена на Mixtral."

#: src/ollama_models.py:2991
msgid "Great code generation model based on Llama2."
msgstr "Отличная модель генерации кода на основе Llama2."

#: src/ollama_models.py:3013
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr ""
"Модель на основе Llama2 без цензуры с поддержкой контекстного окна 16 КБ."

#: src/ollama_models.py:3054
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""

#: src/ollama_models.py:3077
msgid ""
"🎩 Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"🎩 Magicoder — это семейство моделей с 7B параметрами, обученных на 75 000 "
"синтетических данных инструкций с использованием OSS-Instruct, нового "
"подхода к обучению LLM с помощью фрагментов кода с открытым исходным кодом."

#: src/ollama_models.py:3099
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr ""
"Облегченная модель чата, обеспечивающая точный и быстрый вывод без "
"необходимости использования высокопроизводительного оборудования."

#: src/ollama_models.py:3122
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr ""
"Высокопроизводительная модель инструкций кода, созданная путем объединения "
"двух существующих моделей кода."

#: src/ollama_models.py:3145
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2 — это модель причинного декодера с 11B параметров, созданная TII и "
"обученная на токенах 5T."

#: src/ollama_models.py:3167
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr ""
"Wizard Vicuna — это модель с 13B параметрами, основанная на Llama 2, "
"обученная MelodysDreamj."

#: src/ollama_models.py:3189
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr ""
"MistralLite — доработанная модель на базе Mistral с расширенными "
"возможностями обработки длинных контекстов."

#: src/ollama_models.py:3212
msgid ""
"MathΣtral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr ""

#: src/ollama_models.py:3234
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr ""
"Модель преобразования текста в SQL с 7B параметрами, созданная MotherDuck и "
"Numbers Station."

#: src/ollama_models.py:3255
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b — это трансформация Dolphin-2.2-70b, созданная путем "
"чередования модели самой с собой."

#: src/ollama_models.py:3277
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""

#: src/ollama_models.py:3304
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""

#: src/ollama_models.py:3325
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr ""
"Высокоэффективная модель экспертной модели, точно настроенная на основе "
"высококачественных данных."

#: src/ollama_models.py:3347
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr ""
"Модель чата 7B, настроенная на основе высококачественных данных и основанная "
"на Zephyr."

#: src/ollama_models.py:3370
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"Слияние модели Open Orca OpenChat и модели Garage-bAInd Platypus 2. "
"Предназначен для чата и генерации кода."

#: src/ollama_models.py:3387
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr ""
"Языковая модель, созданная путем объединения двух точно настроенных моделей "
"Llama 2 70B в одну."

#: src/ollama_models.py:3428
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""

#: src/ollama_models.py:3450
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""

#: src/ollama_models.py:3501
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr ""

#: src/ollama_models.py:3523
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr "DBRX — это открытая LLM общего назначения, созданная Databricks."

#: src/ollama_models.py:3545
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""

#: src/ollama_models.py:3568
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr "Встраиваемая модель из BAAI, преобразующая тексты в векторы."

#: src/ollama_models.py:3590
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr ""

#: src/ollama_models.py:3611
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr ""
"Надежная диалоговая модель, предназначенная для использования как в чате, "
"так и для инструкций."

#: src/ollama_models.py:3633
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""

#: src/ollama_models.py:3666
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""

#: src/ollama_models.py:3688
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr ""

#: src/ollama_models.py:3716
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""

#: src/ollama_models.py:3740
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr ""

#: src/ollama_models.py:3770
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""

#: src/ollama_models.py:3799
msgid ""
"Tülu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""

#: src/ollama_models.py:3827
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""

#: src/ollama_models.py:3855
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr ""

#: src/ollama_models.py:3889
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""

#: src/ollama_models.py:3937
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr ""

#: src/ollama_models.py:3975
msgid ""
"A family of efficient AI models under 10B parameters performant in science, "
"math, and coding through innovative training techniques."
msgstr ""

#: src/ollama_models.py:4016
msgid ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."
msgstr ""

#: src/ollama_models.py:4057
msgid ""
"The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""

#: src/ollama_models.py:4098
msgid ""
"The IBM Granite Embedding 30M and 278M models models are text-only dense "
"biencoder embedding models, with 30M available in English only and 278M "
"serving multilingual use cases."
msgstr ""

#: src/ollama_models.py:4120
msgid "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft."
msgstr ""

#: src/ollama_models.py:4143
msgid ""
"A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model."
msgstr ""

#: src/ollama_models.py:4167
msgid ""
"Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of "
"instruct-tuned models designed to be the ultimate general purpose local "
"model, enabling coding, math, agentic, function calling, and general use "
"cases."
msgstr ""

#: src/ollama_models.py:4218
msgid ""
"DeepSeek's first-generation of reasoning models with comparable performance "
"to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on "
"Llama and Qwen."
msgstr ""

#: src/ollama_models.py:4239
msgid ""
"A strong Mixture-of-Experts (MoE) language model with 671B total parameters "
"with 37B activated for each token."
msgstr ""

#: src/ollama_models.py:4266
msgid ""
"OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. "
"These models are on par with or better than equivalently sized fully open "
"models, and competitive with open-weight models such as Llama 3.1 on English "
"academic benchmarks."
msgstr ""

#: src/ollama_models.py:4314
msgid ""
"The smallest model in Cohere's R series delivers top-tier speed, efficiency, "
"and quality to build powerful AI applications on commodity GPUs and edge "
"devices."
msgstr ""

#: src/ollama_models.py:4342
msgid ""
"A fully open-source family of reasoning models built using a dataset derived "
"by distilling DeepSeek-R1."
msgstr ""

#: src/ollama_models.py:4366
msgid ""
"A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the "
"performance of OpenAI’s o1-preview with just 1.5B parameters on popular math "
"evaluations."
msgstr ""

#: src/ollama_models.py:4396
msgid ""
"A version of the DeepSeek-R1 model that has been post trained to provide "
"unbiased, accurate, and factual information by Perplexity."
msgstr ""

#: src/ollama_models.py:4433
msgid "The current, most capable model that runs on a single GPU."
msgstr "Текущая, самая производительная модель, работающая на одном GPU."

#: src/ollama_models.py:4480
msgid ""
"Phi-4-mini brings significant enhancements in multilingual support, "
"reasoning, and mathematics, and now, the long-awaited function calling "
"feature is finally supported."
msgstr ""

#: src/ollama_models.py:4504
msgid ""
"A compact and efficient vision-language model, specifically designed for "
"visual document understanding, enabling automated content extraction from "
"tables, charts, infographics, plots, diagrams, and more."
msgstr ""

#: src/ollama_models.py:4544
msgid ""
"Granite-3.2 is a family of long-context AI models from IBM Granite fine-"
"tuned for thinking capabilities."
msgstr ""

#: src/ollama_models.py:4568
msgid ""
"A new state-of-the-art version of the lightweight Command R7B model that "
"excels in advanced Arabic language capabilities for enterprises in the "
"Middle East and Northern Africa."
msgstr ""

#: src/ollama_models.py:4614
msgid ""
"111 billion parameter model optimized for demanding enterprises that require "
"fast, secure, and high-quality AI"
msgstr ""

#: src/ollama_models.py:4655
msgid ""
"Qwen3 is the latest generation of large language models in Qwen series, "
"offering a comprehensive suite of dense and mixture-of-experts (MoE) models."
msgstr ""

#: src/ollama_models.py:4802
msgid "Devstral: the best open source model for coding agents"
msgstr ""

#: src/ollama_models.py:4830
msgid "Meta's latest collection of multimodal models."
msgstr ""

#: src/ollama_models.py:4878
msgid ""
"Flagship vision-language model of Qwen and also a significant leap from the "
"previous Qwen2-VL."
msgstr ""

#: src/ollama_models.py:4908
msgid ""
"DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a "
"1.5B version also available."
msgstr ""

#: src/ollama_models.py:4933
msgid ""
"Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-"
"art vision understanding and enhances long context capabilities up to 128k "
"tokens without compromising text performance."
msgstr ""

#: src/ollama_models.py:4973
msgid ""
"Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that "
"outperform the best available open models of the same size, including "
"counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks."
msgstr ""

#: src/ollama_models.py:5002
msgid ""
"IBM Granite 2B and 8B models are 128K context length language models that "
"have been fine-tuned for improved reasoning and instruction-following "
"capabilities."
msgstr ""

#: src/ollama_models.py:5040
msgid ""
"Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight "
"reasoning models that rival much larger models on complex reasoning tasks."
msgstr ""

#: src/ollama_models.py:5073
msgid ""
"EXAONE Deep exhibits superior capabilities in various reasoning tasks "
"including math and coding benchmarks, ranging from 2.4B to 32B parameters "
"developed and released by LG AI Research."
msgstr ""

#: src/ollama_models.py:5100
msgid ""
"Phi 4 mini reasoning is a lightweight open model that balances efficiency "
"with advanced reasoning ability."
msgstr ""

#: src/window.py:156
msgid "Ollama Was Not Found"
msgstr ""

#: src/window.py:157
msgid ""
"To add a managed Ollama instance, you must have Ollama installed locally in "
"your device, this is a simple process and should not take more than 5 "
"minutes."
msgstr ""

#: src/window.py:159
msgid "Open Tutorial in Web Browser"
msgstr ""

#: src/window.py:165 src/window.py:173 src/window.ui:496 src/window.ui:506
#: src/window.ui:528
msgid "Add Instance"
msgstr "Добавить экземпляр"

#: src/window.py:174
msgid "Select a type of instance to add"
msgstr "Выберите тип экземпляра для добавления"

#: src/window.py:387
msgid "No tools enabled."
msgstr ""

#: src/window.py:387
msgid "Open Tool Manager"
msgstr ""

#: src/window.py:390
msgid "Please select a model before chatting"
msgstr "Пожалуйста, выберите модель перед началом общения"

#: src/window.py:463 src/window.py:464 src/window.py:559 src/window.ui:355
msgid "Close"
msgstr "Закрыть"

#: src/window.py:466 src/window.py:467 src/window.ui:62 src/window.ui:63
msgid "Next"
msgstr "Следующий"

#: src/window.py:557 src/window.ui:992 src/window.ui:996
#: src/widgets/dialog.py:150 src/widgets/dialog.py:163
#: src/widgets/dialog.py:176 src/widgets/instance_manager.py:470
#: src/widgets/instance_manager.py:471 src/widgets/model_manager.py:644
#: src/widgets/blocks/code.py:136 src/widgets/blocks/text.py:111
#: src/widgets/tools/tools.py:132
msgid "Cancel"
msgstr "Отмена"

#: src/window.py:558
msgid "Hide"
msgstr "Скрыть"

#: src/window.py:562
msgid "Close Alpaca?"
msgstr "Закрыть Alpaca?"

#: src/window.py:563
msgid "A task is currently in progress. Are you sure you want to close Alpaca?"
msgstr ""
"Задача в настоящее время выполняется. Вы уверены, что хотите закрыть Alpaca?"

#: src/window.py:775 src/window.ui:163 src/window.ui:1232
#: src/widgets/chat.py:206 src/widgets/instance_manager.py:58
#: src/widgets/instance_manager.py:69 src/widgets/instance_manager.py:110
msgid "New Chat"
msgstr "Новый Чат"

#: src/window.py:855
msgid "This video does not have any transcriptions"
msgstr "В этом видео нет никаких расшифровок"

#: src/window.py:863
msgid "Attach YouTube Video?"
msgstr "Прикрепить видео с YouTube?"

#: src/window.py:864
msgid ""
"{}\n"
"\n"
"Please select a transcript to include"
msgstr ""
"{}\n"
"\n"
"Пожалуйста, выберите расшифровку для включения"

#: src/window.py:870
msgid "Error attaching video, please try again"
msgstr ""

#: src/window.py:892 src/window.py:1259
msgid "Attach Website? (Experimental)"
msgstr "Прикрепить веб-сайт? (Экспериментальный)"

#: src/window.py:893
msgid ""
"Are you sure you want to attach\n"
"'{}'?"
msgstr ""
"Вы уверены, что хотите прикрепить\n"
"\"{}\"?"

#: src/window.py:912 src/window.py:1256
msgid "Image recognition is only available on specific models"
msgstr "Распознавание изображений доступно только на определенных моделях"

#: src/window.py:1038
msgid "Chat imported successfully"
msgstr "Чат успешно импортирован"

#: src/window.py:1052
msgid "Attachment failed, screenshot might be too big"
msgstr ""

#: src/window.py:1101
msgid "Any compatible Alpaca attachment"
msgstr ""

#: src/window.py:1227
msgid "Attach Screenshot"
msgstr ""

#: src/window.py:1260
msgid "Please enter a website URL"
msgstr "Введите URL-адрес веб-сайта"

#: src/window.py:1266
msgid "Attach YouTube Captions?"
msgstr "Прикрепить субтитры YouTube?"

#: src/window.py:1267
msgid "Please enter a YouTube video URL"
msgstr "Введите URL-адрес видео YouTube."

#: src/window.py:1275
msgid "Download Model?"
msgstr "Загрузить модель?"

#: src/window.py:1276
msgid "Please enter the model name following this template: name:tag"
msgstr ""
"Пожалуйста, введите название модели в соответствии с этим шаблоном: name:tag"

#: src/window.py:1283
msgid "Delete All Chats?"
msgstr "Удалить все чаты?"

#: src/window.py:1284
msgid "Are you sure you want to delete all chats?"
msgstr "Вы уверены, что хотите удалить все чаты?"

#: src/window.py:1286 src/widgets/attachments.py:211 src/widgets/chat.py:459
msgid "Delete"
msgstr "Удалить"

#: src/window.py:1313
msgid "Already Installed!"
msgstr ""

#: src/window.ui:34
msgid "Welcome"
msgstr ""

#: src/window.ui:46 src/window.ui:47
msgid "Previous"
msgstr "Предыдущий"

#: src/window.ui:82
msgid "Welcome to Alpaca"
msgstr "Добро пожаловать в Alpaca"

#: src/window.ui:83
msgid "Powering your potential"
msgstr ""

#: src/window.ui:91
msgid ""
"Alpaca and its developers are not liable for any damages to devices or "
"software resulting from the execution of code generated by an AI model. "
"Please exercise caution and review the code carefully before running it.\n"
"\n"
"Alpaca is distributed under GPL v3.0, this software comes with no warranty."
msgstr ""

#: src/window.ui:100
msgid "Effortless Code Execution"
msgstr ""

#: src/window.ui:101
msgid ""
"Alpaca can run Python, C++, and even HTML (with a live server) right from "
"your conversations. Give it a try!"
msgstr ""

#: src/window.ui:107
msgid "Private by Design"
msgstr ""

#: src/window.ui:108
msgid ""
"With Alpaca, your conversations are saved locally on your device, so you can "
"be confident that your data is always secure and private."
msgstr ""

#: src/window.ui:114
msgid "Local AI"
msgstr "Локальный ИИ"

#: src/window.ui:115
msgid ""
"Alpaca works with AI providers such as Gemini and ChatGPT.  To run AI models "
"locally on your machine, you'll need to install Ollama within Alpaca. We've "
"made it super easy to do, so you can get started quickly!"
msgstr ""

#: src/window.ui:120 src/window.ui:121
msgid "Install Ollama"
msgstr "Установить Ollama"

#: src/window.ui:174
msgid "Menu"
msgstr "Меню"

#: src/window.ui:181
msgid "Search Chats"
msgstr ""

#: src/window.ui:190
msgid "Chat search bar"
msgstr ""

#: src/window.ui:198 src/window.ui:200
msgid "Search chats"
msgstr ""

#: src/window.ui:236
msgid "No Chats Found"
msgstr ""

#: src/window.ui:237
msgid "Oh no! It looks like there are no chats found for your search."
msgstr ""

#: src/window.ui:254
msgid "Toggle Sidebar"
msgstr "Переключение боковой панели"

#: src/window.ui:261
msgid "Search Messages"
msgstr ""

#: src/window.ui:278 src/window.ui:303 src/window.ui:1256
msgid "Manage Models"
msgstr "Управление Моделями"

#: src/window.ui:299
msgid "Add Models"
msgstr "Добавить модели"

#: src/window.ui:316
msgid "Chat Menu"
msgstr "Меню чата"

#: src/window.ui:329
msgid "Message search bar"
msgstr "Панель поиска сообщений"

#: src/window.ui:338 src/window.ui:340
msgid "Search messages"
msgstr ""

#: src/window.ui:356
msgid ""
"Warning: Power saver mode is enabled, this will slow down message generation"
msgstr ""

#: src/window.ui:391 src/window.ui:1354
msgid "Attach File"
msgstr "Прикрепить файл"

#: src/window.ui:428
msgid "Send Message"
msgstr "Отправить Сообщение"

#: src/window.ui:447
msgid "Stop Message"
msgstr ""

#: src/window.ui:477
msgid "Instance Manager"
msgstr "Менеджер экземпляров"

#: src/window.ui:492
msgid "No Instances Found"
msgstr "Экземпляры не найдены"

#: src/window.ui:493
msgid "It looks a bit empty in here. Try adding an instance get started!"
msgstr ""

#: src/window.ui:522
msgid "Added Instances"
msgstr ""

#: src/window.ui:523
msgid ""
"Manage your AI instances, chats and messages are shared between instances "
"when generating responses."
msgstr ""

#: src/window.ui:559
msgid "Tool Manager"
msgstr "Менеджер инструментов"

#: src/window.ui:570
msgid "Available Tools"
msgstr "Доступные инструменты"

#: src/window.ui:571
msgid ""
"Functions that AI models might use when sending a message by selecting \"Use "
"Tools\" in the send button context menu."
msgstr ""

#: src/window.ui:590
msgid "Model Manager"
msgstr "Менеджер моделей"

#: src/window.ui:628
msgid "Search Model"
msgstr "Поиск модели"

#: src/window.ui:642
msgid "Model Manager Menu"
msgstr "Меню менеджера моделей"

#: src/window.ui:655
msgid "Model search bar"
msgstr "Панель поиска модели"

#: src/window.ui:667 src/window.ui:669
msgid "Search models"
msgstr "Поиск моделей"

#: src/window.ui:676
msgid "Filter Models"
msgstr ""

#: src/window.ui:692
msgid "Added"
msgstr "Добавлено"

#: src/window.ui:702 src/window.ui:763 src/window.ui:817
msgid "No Models Found"
msgstr "Модели не найдены"

#: src/window.ui:703
msgid ""
"It looks a bit empty in here. Try downloading some models or change your AI "
"instance to get started!"
msgstr ""

#: src/window.ui:706 src/window.ui:716 src/window.ui:1252
msgid "Manage Instances"
msgstr "Управление экземплярами"

#: src/window.ui:764 src/window.ui:818
msgid ""
"Looks like we’re fresh out of models for that search. Try tweaking your "
"keywords, or maybe explore something new!"
msgstr ""

#: src/window.ui:776
msgid "Available"
msgstr ""

#: src/window.ui:830
msgid "Creator"
msgstr ""

#: src/window.ui:841
msgid "Model Creator"
msgstr ""

#: src/window.ui:842
msgid "Select a method of importing a model to continue"
msgstr "Выберите способ импорта модели для продолжения"

#: src/window.ui:854
msgid "GGUF File"
msgstr ""

#: src/window.ui:865
msgid "Existing Model"
msgstr ""

#: src/window.ui:883
msgid "Identity"
msgstr ""

#: src/window.ui:886
msgid "Base"
msgstr "Основа"

#: src/window.ui:893
msgid "Profile Picture"
msgstr ""

#: src/window.ui:898
msgid "Open File"
msgstr "Открыть файл"

#: src/window.ui:909 src/widgets/instance_manager.py:278
msgid "Name"
msgstr "Имя"

#: src/window.ui:914 src/widgets/model_manager.py:478
msgid "Tag"
msgstr "Тэг"

#: src/window.ui:921 src/widgets/model_manager.py:495
msgid "Context"
msgstr "Контекст"

#: src/window.ui:922
msgid ""
"Describe the desired behavior of the model in its primary language "
"(typically English)."
msgstr ""

#: src/window.ui:950
msgid "Behavior"
msgstr "Поведение"

#: src/window.ui:953
msgid "Imagination"
msgstr "Воображение"

#: src/window.ui:954
msgid "A higher number results in more diverse answers from the model. (top_k)"
msgstr ""
"Большее число результатов приводит к более разнообразным ответам модели. "
"(top_k)"

#: src/window.ui:968
msgid "Focus"
msgstr ""

#: src/window.ui:969
msgid "A higher number widens the amount of possible answers. (top_p)"
msgstr "Чем больше число, тем больше количество возможных ответов. (top_p)"

#: src/window.ui:1002 src/window.ui:1010
msgid "Add Model"
msgstr "Добавить модель"

#: src/window.ui:1044 src/window.ui:1266
msgid "Preferences"
msgstr "Настройки"

#: src/window.ui:1052
msgid "Run Alpaca In Background"
msgstr "Запуск Alpaca в фоновом режиме"

#: src/window.ui:1059
msgid "Show Power Saver Warning"
msgstr ""

#: src/window.ui:1060
msgid "When running a managed Ollama instance"
msgstr ""

#: src/window.ui:1067
msgid "Zoom"
msgstr ""

#: src/window.ui:1084
msgid "Speech Recognition Model"
msgstr ""

#: src/window.ui:1085
msgid ""
"Models are downloaded upon first use, you can delete them from the model "
"manager"
msgstr ""

#: src/window.ui:1092
msgid "Speech Recognition Language"
msgstr ""

#: src/window.ui:1099
msgid "Auto Send Message After Talking"
msgstr ""

#: src/window.ui:1110
msgid "Default Text to Speech Voice"
msgstr ""

#: src/window.ui:1111
msgid ""
"Voices are downloaded upon first use, each weighing around 1 MB, and you can "
"delete them from the model manager"
msgstr ""

#: src/window.ui:1118
msgid "Dictate New Messages Automatically"
msgstr ""

#: src/window.ui:1119
msgid "Dictate new messages once they have finished being generated"
msgstr ""

#: src/window.ui:1132
msgid "Delete All Chats"
msgstr "Удалить все чаты"

#: src/window.ui:1144
msgid "Notice"
msgstr "Уведомление"

#: src/window.ui:1164
msgid ""
"Hey Alpaca users! We're so excited to bring you a fresh update packed with "
"awesome new features to explore! Get ready to experience Alpaca in a whole "
"new way!"
msgstr ""

#: src/window.ui:1171
msgid "Smart Tools"
msgstr ""

#: src/window.ui:1172
msgid ""
"Supported AI models can use handy tools to grab information both locally and "
"online. Head over to the brand new \"Tool Manager\" to toggle them on or off."
msgstr ""

#: src/window.ui:1179
msgid "Talk to Models"
msgstr ""

#: src/window.ui:1180
msgid ""
"You can now dictate your messages using local speech recognition. It's super "
"convenient! You can even customize your language and other settings in the "
"Preferences dialog."
msgstr ""

#: src/window.ui:1187
msgid "Find Models Faster"
msgstr ""

#: src/window.ui:1188
msgid ""
"Browsing through your Ollama models just got easier! We've added the ability "
"to filter models by their categories in the Model Manager. Now you can "
"quickly find exactly the model you're looking for."
msgstr ""

#: src/window.ui:1195
msgid "Math Rendering"
msgstr ""

#: src/window.ui:1196
msgid ""
"We've improved how LaTeX equations are rendered in messages, making them "
"look cleaner and more consistent. Your mathematical discussions will be "
"clearer than ever!"
msgstr ""

#: src/window.ui:1203
msgid "More Instances"
msgstr ""

#: src/window.ui:1204
msgid ""
"Get ready to connect Alpaca to a whole universe of AI providers! We've added "
"support for over 5 new AI instance providers, including Anthropic, "
"OpenRouter, and Fireworks. The possibilities are endless!"
msgstr ""

#: src/window.ui:1211
msgid "Attachment Enhancement"
msgstr ""

#: src/window.ui:1212
msgid ""
"You can now attach and ask questions about even more file types, "
"including .docx, .pptx, and .xlsx! Plus, when you preview an attachment, "
"you'll see it with rich text styling, making it easier to understand the "
"content before you send it."
msgstr ""

#: src/window.ui:1236 src/widgets/chat.py:20
msgid "New Notebook"
msgstr ""

#: src/window.ui:1244
msgid "Start Quick Ask"
msgstr ""

#: src/window.ui:1248
msgid "Import Chat"
msgstr "Импорт Чата"

#: src/window.ui:1260
msgid "Manage Tools"
msgstr ""

#: src/window.ui:1270
msgid "Keyboard Shortcuts"
msgstr "Комбинации Клавиш"

#: src/window.ui:1274
msgid "About Alpaca"
msgstr "О Программе"

#: src/window.ui:1282 src/window.ui:1316
msgid "Rename Chat"
msgstr "Переименовать Чат"

#: src/window.ui:1286 src/window.ui:1320
msgid "Duplicate Chat"
msgstr "Дублировать чат"

#: src/window.ui:1290 src/window.ui:1324 src/widgets/chat.py:557
msgid "Export Chat"
msgstr "Экспорт Чата"

#: src/window.ui:1296 src/window.ui:1330
msgid "Delete Chat"
msgstr "Удалить Чат"

#: src/window.ui:1304
msgid "Reload Added Models"
msgstr "Перезагрузить добавленные модели"

#: src/window.ui:1308
msgid "Download Model From Name"
msgstr ""

#: src/window.ui:1338
msgid "Send as User"
msgstr "Отправить как пользователь"

#: src/window.ui:1342
msgid "Send as System"
msgstr "Отправить как системный"

#: src/window.ui:1346 src/gtk/help-overlay.ui:133
msgid "Use Tools"
msgstr ""

#: src/window.ui:1358
msgid "Attach Website"
msgstr "Прикрепить веб-сайт"

#: src/window.ui:1362
msgid "Attach YouTube Captions"
msgstr "Прикрепить субтитры YouTube"

#: src/gtk/help-overlay.ui:11
msgctxt "shortcut window"
msgid "General"
msgstr "Общие"

#: src/gtk/help-overlay.ui:14
msgctxt "shortcut window"
msgid "Show Shortcuts"
msgstr "Показывать комбинации клавиш"

#: src/gtk/help-overlay.ui:20
msgctxt "shortcut window"
msgid "Preferences"
msgstr "Настройки"

#: src/gtk/help-overlay.ui:26
msgctxt "shortcut window"
msgid "Quick Ask"
msgstr ""

#: src/gtk/help-overlay.ui:32
msgctxt "shortcut window"
msgid "Model Manager"
msgstr "Менеджер моделей"

#: src/gtk/help-overlay.ui:38
msgctxt "shortcut window"
msgid "Instance Manager"
msgstr "Менеджер экземпляров"

#: src/gtk/help-overlay.ui:44
msgctxt "shortcut window"
msgid "Action Manager"
msgstr "Менеджер действий"

#: src/gtk/help-overlay.ui:50
msgctxt "shortcut window"
msgid "Toggle Sidebar"
msgstr "Переключение боковой панели"

#: src/gtk/help-overlay.ui:56
msgctxt "shortcut window"
msgid "Quit"
msgstr "Выйти"

#: src/gtk/help-overlay.ui:64
msgctxt "shortcut window"
msgid "Chat Management"
msgstr "Управление чатом"

#: src/gtk/help-overlay.ui:67
msgctxt "shortcut window"
msgid "Create Chat"
msgstr "Создать чат"

#: src/gtk/help-overlay.ui:73
msgctxt "shortcut window"
msgid "Delete Chat"
msgstr "Удалить чат"

#: src/gtk/help-overlay.ui:79
msgctxt "shortcut window"
msgid "Clear Chat"
msgstr "Очистить чат"

#: src/gtk/help-overlay.ui:85
msgctxt "shortcut window"
msgid "Rename Chat"
msgstr "Переименовать чат"

#: src/gtk/help-overlay.ui:91
msgctxt "shortcut window"
msgid "Toggle Searchbars"
msgstr ""

#: src/gtk/help-overlay.ui:99
msgctxt "shortcut window"
msgid "Message Entry"
msgstr ""

#: src/gtk/help-overlay.ui:102
msgid "Copy"
msgstr "Копировать"

#: src/gtk/help-overlay.ui:108
msgid "Paste"
msgstr "Вставить"

#: src/gtk/help-overlay.ui:114
msgid "Open Emoji Menu"
msgstr "Откройте меню Эмодзи"

#: src/gtk/help-overlay.ui:120
msgid "Insert new line"
msgstr "Вставить новую строку"

#: src/gtk/help-overlay.ui:126
msgid "Send Message as System"
msgstr "Отправить сообщение как системное"

#: src/gtk/help-overlay.ui:127
msgid "System messages are taken as literal instructions by models"
msgstr "Системные сообщения воспринимаются моделями как буквальные инструкции"

#: src/gtk/help-overlay.ui:134
msgid "Ask model to use tools to generate a message"
msgstr ""

#: src/gtk/help-overlay.ui:140
msgid "Send Message as User"
msgstr "Отправить сообщение как пользователь"

#: src/widgets/attachments.py:124
msgid "Remove Attachment"
msgstr "Удалить вложение"

#: src/widgets/attachments.py:138
msgid "Replace Notebook Content"
msgstr ""

#: src/widgets/attachments.py:208
msgid "Delete Attachment?"
msgstr ""

#: src/widgets/attachments.py:209 src/widgets/chat.py:457
msgid "Are you sure you want to delete '{}'?"
msgstr "Вы уверены, что хотите удалить '{}'?"

#: src/widgets/attachments.py:285
msgid "Image"
msgstr "Изображение"

#: src/widgets/attachments.py:296 src/widgets/attachments.py:308
msgid "Missing Image"
msgstr "Изображение Отсутствует"

#: src/widgets/chat.py:86 src/widgets/instance_manager.py:96
msgid "Notebook"
msgstr ""

#: src/widgets/chat.py:87
msgid "Start a notebook with a message"
msgstr ""

#: src/widgets/chat.py:95 src/widgets/chat.py:247
msgid "No Messages Found"
msgstr ""

#: src/widgets/chat.py:96 src/widgets/chat.py:248
msgid "Uh oh! No messages found for your search."
msgstr ""

#: src/widgets/chat.py:238
msgid "Try one of these prompts"
msgstr "Попробуйте один из этих промптов"

#: src/widgets/chat.py:268
msgid "Send prompt: '{}'"
msgstr ""

#: src/widgets/chat.py:274
msgid "Refresh Prompts"
msgstr ""

#: src/widgets/chat.py:435
msgid "Rename Chat?"
msgstr "Переименовать чат?"

#: src/widgets/chat.py:436
msgid "Renaming '{}'"
msgstr "Переименование '{}'"

#: src/widgets/chat.py:438
msgid "Chat name"
msgstr "Имя чата"

#: src/widgets/chat.py:439
msgid "Rename"
msgstr "Переименовать"

#: src/widgets/chat.py:456
msgid "Delete Chat?"
msgstr "Удалить чат?"

#: src/widgets/chat.py:464
msgid "Copy of {}"
msgstr ""

#: src/widgets/chat.py:477
msgid "Chat exported successfully"
msgstr "Чат успешно экспортирован"

#: src/widgets/chat.py:497
msgid "User"
msgstr ""

#: src/widgets/chat.py:501
msgid "System"
msgstr ""

#: src/widgets/chat.py:549
msgid "Importable (.db)"
msgstr ""

#: src/widgets/chat.py:550
msgid "Markdown"
msgstr ""

#: src/widgets/chat.py:551
msgid "Markdown (Obsidian Style)"
msgstr ""

#: src/widgets/chat.py:552
msgid "JSON"
msgstr ""

#: src/widgets/chat.py:553
msgid "JSON (Include Metadata)"
msgstr ""

#: src/widgets/chat.py:558
msgid "Select a method to export the chat"
msgstr ""

#: src/widgets/dialog.py:148 src/widgets/dialog.py:161
#: src/widgets/dialog.py:174 src/widgets/tools/tools.py:136
msgid "Accept"
msgstr "Принять"

#: src/widgets/instance_manager.py:30 src/widgets/instance_manager.py:430
msgid "Instance"
msgstr "Образец"

#: src/widgets/instance_manager.py:88
msgid "Notebook Error"
msgstr ""

#: src/widgets/instance_manager.py:89 src/widgets/instance_manager.py:159
msgid "An error occurred while running tool"
msgstr "Во время запуска инструмента произошла ошибка"

#: src/widgets/instance_manager.py:116
msgid "Selecting tool to use..."
msgstr "Выбор инструмента для использования..."

#: src/widgets/instance_manager.py:125
msgid "Using {}"
msgstr "Использование"

#: src/widgets/instance_manager.py:158
msgid "Tool Error"
msgstr "Ошибка инструмента"

#: src/widgets/instance_manager.py:165
msgid "Generating message..."
msgstr "Генерация сообщения..."

#: src/widgets/instance_manager.py:219 src/widgets/instance_manager.py:529
#: src/widgets/instance_manager.py:543 src/widgets/instance_manager.py:693
#: src/widgets/instance_manager.py:775 src/widgets/instance_manager.py:822
#: src/widgets/instance_manager.py:856 src/widgets/instance_manager.py:903
#: src/widgets/instance_manager.py:928 src/widgets/instance_manager.py:954
msgid "Instance Error"
msgstr "Ошибка экземпляра"

#: src/widgets/instance_manager.py:220
msgid "Message generation failed"
msgstr "Не удалось сгенерировать сообщение"

#: src/widgets/instance_manager.py:286
msgid "Port"
msgstr "Порт"

#: src/widgets/instance_manager.py:287
msgid "Which network port will '{}' use"
msgstr ""

#: src/widgets/instance_manager.py:301
msgid "Instance URL"
msgstr "URL-адрес экземпляра"

#: src/widgets/instance_manager.py:304 src/widgets/instance_manager.py:314
#: src/widgets/instance_manager.py:317 src/widgets/instance_manager.py:319
msgid "API Key (Unchanged)"
msgstr ""

#: src/widgets/instance_manager.py:304 src/widgets/instance_manager.py:314
msgid "API Key (Optional)"
msgstr "API ключ (необязательный)"

#: src/widgets/instance_manager.py:317 src/widgets/instance_manager.py:319
msgid "API Key"
msgstr "API ключ"

#: src/widgets/instance_manager.py:327
msgid "Max Tokens"
msgstr ""

#: src/widgets/instance_manager.py:328
msgid ""
"Defines the maximum number of tokens (words + spaces) the AI can generate in "
"a response. More tokens allow longer replies but may take more time and cost "
"more."
msgstr ""

#: src/widgets/instance_manager.py:343
msgid "Temperature"
msgstr "Температура"

#: src/widgets/instance_manager.py:344
msgid "Increasing the temperature will make the models answer more creatively."
msgstr ""

#: src/widgets/instance_manager.py:359
msgid "Seed"
msgstr "Зерно"

#: src/widgets/instance_manager.py:360
msgid ""
"Setting this to a specific number other than 0 will make the model generate "
"the same text for the same prompt."
msgstr ""

#: src/widgets/instance_manager.py:375
msgid "Overrides"
msgstr ""

#: src/widgets/instance_manager.py:375
msgid ""
"These entries are optional, they are used to troubleshoot GPU related "
"problems with Ollama."
msgstr ""

#: src/widgets/instance_manager.py:393
msgid "Model Directory"
msgstr "Каталог моделей"

#: src/widgets/instance_manager.py:395
msgid "Select Directory"
msgstr "Выберите каталог"

#: src/widgets/instance_manager.py:410
msgid "Default Model"
msgstr "Модель по умолчанию"

#: src/widgets/instance_manager.py:410
msgid "Model to select when starting a new chat."
msgstr "Модель для выбора при начале нового чата"

#: src/widgets/instance_manager.py:412
msgid "Title Model"
msgstr ""

#: src/widgets/instance_manager.py:412
msgid "Model to use when generating a chat title."
msgstr "Модель, используемая при создании заголовка чата."

#: src/widgets/instance_manager.py:477 src/widgets/instance_manager.py:478
#: src/widgets/blocks/code.py:145 src/widgets/blocks/text.py:120
msgid "Save"
msgstr "Сохранить"

#: src/widgets/instance_manager.py:530 src/widgets/instance_manager.py:776
#: src/widgets/instance_manager.py:823 src/widgets/instance_manager.py:857
msgid "Could not retrieve added models"
msgstr "Не удалось получить добавленные модели"

#: src/widgets/instance_manager.py:544
msgid "Could not retrieve available models"
msgstr "Не удалось получить доступные модели"

#: src/widgets/instance_manager.py:613
msgid "Ollama (Managed)"
msgstr ""

#: src/widgets/instance_manager.py:622
msgid "Local AI instance managed directly by Alpaca"
msgstr "Локальный экземпляр ИИ, управляемый непосредственно Alpaca"

#: src/widgets/instance_manager.py:645
msgid "Alpaca Support"
msgstr "Поддержка Alpaca"

#: src/widgets/instance_manager.py:652
msgid "Model request too large for system"
msgstr "Запрос модели слишком велик для системы"

#: src/widgets/instance_manager.py:655
msgid "AMD GPU detected but the extension is missing, Ollama will use CPU."
msgstr ""
"Обнаружен графический процессор AMD, но расширение отсутствует, Ollama будет "
"использовать ЦП"

#: src/widgets/instance_manager.py:657
msgid "AMD GPU detected but ROCm is missing, Ollama will use CPU."
msgstr ""
"Обнаружен графический процессор AMD, но ROCm отсутствует, Ollama будет "
"использовать ЦП"

#: src/widgets/instance_manager.py:659
msgid "Using AMD GPU type '{}'"
msgstr "Использование графического процессора AMD"

#: src/widgets/instance_manager.py:669
msgid "Integrated Ollama instance is not running"
msgstr "Интегрированный экземпляр Ollama не запущен"

#: src/widgets/instance_manager.py:694
msgid "Managed Ollama instance failed to start"
msgstr "Управляемый экземпляр Ollama не запустился"

#: src/widgets/instance_manager.py:699
msgid "Integrated Ollama instance is running"
msgstr "Интегрированный экземпляр Ollama запущен"

#: src/widgets/instance_manager.py:704 src/widgets/instance_manager.py:707
msgid "Ollama Log"
msgstr ""

#: src/widgets/instance_manager.py:724
msgid "Local or remote AI instance not managed by Alpaca"
msgstr "Локальный или удаленный экземпляр ИИ не управляется Alpaca"

#: src/widgets/instance_manager.py:904 src/widgets/instance_manager.py:929
#: src/widgets/instance_manager.py:955
msgid "Could not retrieve models"
msgstr "Не удалось получить модели"

#: src/widgets/instance_manager.py:915
msgid "Fireworks AI inference platform"
msgstr ""

#: src/widgets/instance_manager.py:940
msgid "Lambda Labs cloud inference API"
msgstr ""

#: src/widgets/instance_manager.py:966
msgid "Cerebras AI cloud inference API"
msgstr ""

#: src/widgets/instance_manager.py:972
msgid "Kluster AI cloud inference API"
msgstr ""

#: src/widgets/instance_manager.py:976
msgid "OpenAI Compatible Instance"
msgstr "Экземпляр, совместимый с Openal"

#: src/widgets/instance_manager.py:977
msgid "AI instance compatible with OpenAI library"
msgstr ""

#: src/widgets/instance_manager.py:987
msgid "Meta AI Llama API"
msgstr ""

#: src/widgets/instance_manager.py:1008
msgid "Remove Instance?"
msgstr "Удалить экземпляр"

#: src/widgets/instance_manager.py:1009
msgid "Are you sure you want to remove this instance?"
msgstr "Вы уверены, что хотите удалить этот экземпляр?"

#: src/widgets/instance_manager.py:1011 src/widgets/model_manager.py:114
#: src/widgets/model_manager.py:201 src/widgets/model_manager.py:645
#: src/widgets/model_manager.py:702
msgid "Remove"
msgstr "Удалить"

#: src/widgets/instance_manager.py:1029
msgid "Edit Instance"
msgstr ""

#: src/widgets/message.py:33
msgid "Remove Message"
msgstr "Удалить Сообщение"

#: src/widgets/message.py:43
msgid "Copy Message"
msgstr "Копировать Сообщение"

#: src/widgets/message.py:53
msgid "Edit Message"
msgstr "Изменить Сообщение"

#: src/widgets/message.py:64
msgid "Regenerate Message"
msgstr ""

#: src/widgets/message.py:76
msgid "Dictate Message"
msgstr ""

#: src/widgets/message.py:95
msgid "Message copied to the clipboard"
msgstr "Сообщение скопировано в буфер обмена"

#: src/widgets/message.py:144
msgid "Text to Speech Error"
msgstr ""

#: src/widgets/message.py:145
msgid "An error occurred while running text to speech model"
msgstr ""

#: src/widgets/message.py:173
msgid "Message cannot be regenerated while receiving a response"
msgstr ""

#: src/widgets/model_manager.py:107 src/widgets/model_manager.py:194
#: src/widgets/model_manager.py:695
msgid "Remove Model"
msgstr "Удалить модель"

#: src/widgets/model_manager.py:111 src/widgets/model_manager.py:198
#: src/widgets/model_manager.py:699
msgid "Remove Model?"
msgstr "Удалить модель?"

#: src/widgets/model_manager.py:112 src/widgets/model_manager.py:199
#: src/widgets/model_manager.py:700
msgid "Are you sure you want to remove '{}'?"
msgstr "Вы уверены, что хотите удалить '{}'?"

#: src/widgets/model_manager.py:122
msgid "Local text to speech model provided by Kokoro."
msgstr ""

#: src/widgets/model_manager.py:159 src/widgets/model_manager.py:293
msgid "Speech to Text"
msgstr ""

#: src/widgets/model_manager.py:209
msgid "Local speech to text model provided by OpenAI Whisper."
msgstr ""

#: src/widgets/model_manager.py:238
msgid "Downloading…"
msgstr ""

#: src/widgets/model_manager.py:248 src/widgets/model_manager.py:250
msgid "Stop Download"
msgstr "Остановить загрузку"

#: src/widgets/model_manager.py:256
msgid "Stop Download?"
msgstr "Остановить загрузку?"

#: src/widgets/model_manager.py:257
msgid "Are you sure you want to stop pulling '{}'?"
msgstr ""

#: src/widgets/model_manager.py:259
msgid "Stop"
msgstr "Стоп"

#: src/widgets/model_manager.py:341
msgid "Model Manager Error"
msgstr ""

#: src/widgets/model_manager.py:342
msgid "An error occurred whilst pulling '{}'"
msgstr ""

#: src/widgets/model_manager.py:372
msgid "Download Completed"
msgstr "Загрузка завершена"

#: src/widgets/model_manager.py:373
msgid "Model '{}' downloaded successfully."
msgstr "Загрузка '{}' завершена."

#: src/widgets/model_manager.py:437
msgid "Change Profile Picture"
msgstr "Изменить иконку профиля"

#: src/widgets/model_manager.py:454
msgid "Voice"
msgstr ""

#: src/widgets/model_manager.py:459
msgid "Default"
msgstr ""

#: src/widgets/model_manager.py:479
msgid "Family"
msgstr ""

#: src/widgets/model_manager.py:480
msgid "Parameter Size"
msgstr ""

#: src/widgets/model_manager.py:481
msgid "Quantization Level"
msgstr ""

#: src/widgets/model_manager.py:484
msgid "Parent Model"
msgstr ""

#: src/widgets/model_manager.py:487 src/widgets/model_manager.py:489
msgid "Modified At"
msgstr ""

#: src/widgets/model_manager.py:497
msgid "Description"
msgstr "Описание"

#: src/widgets/model_manager.py:646
msgid "Change"
msgstr "Изменить"

#: src/widgets/model_manager.py:654
msgid "Model Profile Picture"
msgstr ""

#: src/widgets/model_manager.py:655
msgid "What do you want to do with the model's profile picture?"
msgstr "Что вы хотите сделать с фотографией профиля модели?"

#: src/widgets/model_manager.py:687
msgid "Create Child"
msgstr ""

#: src/widgets/model_manager.py:714
msgid "Multilingual"
msgstr ""

#: src/widgets/model_manager.py:715
msgid "Code"
msgstr ""

#: src/widgets/model_manager.py:716
msgid "Math"
msgstr ""

#: src/widgets/model_manager.py:717
msgid "Vision"
msgstr ""

#: src/widgets/model_manager.py:718
msgid "Embedding"
msgstr ""

#: src/widgets/model_manager.py:719
msgid "Tools"
msgstr ""

#: src/widgets/model_manager.py:720
msgid "Reasoning"
msgstr ""

#: src/widgets/model_manager.py:721
msgid "Small"
msgstr ""

#: src/widgets/model_manager.py:722
msgid "Medium"
msgstr ""

#: src/widgets/model_manager.py:723
msgid "Big"
msgstr "Большой"

#: src/widgets/model_manager.py:724
msgid "Huge"
msgstr "Огромный"

#: src/widgets/model_manager.py:814
msgid ""
"By downloading this model you accept the license agreement available on the "
"model's website"
msgstr ""

#: src/widgets/model_manager.py:895
msgid "Languages"
msgstr ""

#: src/widgets/terminal.py:17
msgid "Setting up Python environment..."
msgstr "Настройка переменной Python..."

#: src/widgets/terminal.py:29
msgid "Using Python HTTP server..."
msgstr ""

#: src/widgets/terminal.py:34
msgid "Using Flatpak contained shell..."
msgstr ""

#: src/widgets/terminal.py:38
msgid "Using SSH to run command"
msgstr ""

#: src/widgets/terminal.py:85
msgid "Terminal"
msgstr "Терминал"

#: src/widgets/terminal.py:97
msgid "Open Environment Directory"
msgstr "Открытый каталог среды"

#: src/widgets/terminal.py:181
msgid "Script Exited"
msgstr ""

#: src/widgets/terminal.py:192
msgid "Alpaca Terminal is not compatible with Windows"
msgstr ""

#: src/widgets/blocks/code.py:84
msgid "Code Block"
msgstr ""

#: src/widgets/blocks/code.py:111
msgid "Edit Script"
msgstr ""

#: src/widgets/blocks/code.py:119
msgid "Copy Script"
msgstr ""

#: src/widgets/blocks/code.py:127
msgid "Run Script"
msgstr "Выполнить скрипт"

#: src/widgets/blocks/code.py:193
msgid "Changes saved successfully"
msgstr ""

#: src/widgets/blocks/code.py:199
msgid "Code copied to the clipboard"
msgstr "Код скопирован в буфер обмена"

#: src/widgets/blocks/latex.py:41
msgid "Copy Equation"
msgstr "Копировать уравнение"

#: src/widgets/blocks/latex.py:76
msgid "Equation copied to the clipboard"
msgstr "Уравнение скопировано в буфер обмена"

#: src/widgets/blocks/__init__.py:36
msgid "Thought"
msgstr ""

#: src/widgets/tools/notebook_tools.py:18
msgid "Read Notebook"
msgstr ""

#: src/widgets/tools/notebook_tools.py:19
msgid "Reads the current notebook."
msgstr ""

#: src/widgets/tools/notebook_tools.py:38
msgid "Write Notebook"
msgstr ""

#: src/widgets/tools/notebook_tools.py:39
msgid "Overwrites the notebook with new text."
msgstr ""

#: src/widgets/tools/notebook_tools.py:58
msgid "Append to Notebook"
msgstr ""

#: src/widgets/tools/notebook_tools.py:59
msgid "Appends text to the notebook."
msgstr ""

#: src/widgets/tools/tools.py:67
msgid "AI Description"
msgstr ""

#: src/widgets/tools/tools.py:68
msgid "The description the AI model will use to understand what the tool does."
msgstr ""

#: src/widgets/tools/tools.py:79
msgid "Arguments"
msgstr ""

#: src/widgets/tools/tools.py:80
msgid "Variables that are filled by the AI."
msgstr ""

#: src/widgets/tools/tools.py:93
msgid "Variables"
msgstr ""

#: src/widgets/tools/tools.py:94
msgid ""
"User filled values that the tool uses to work, the AI does not have access "
"to these variables at all."
msgstr ""

#: src/widgets/tools/tools.py:182
msgid "Gets the current date and/or time."
msgstr ""

#: src/widgets/tools/tools.py:215
msgid "Gets a recipe by the meal's name"
msgstr ""

#: src/widgets/tools/tools.py:230 src/widgets/tools/tools.py:297
msgid "YouTube Video"
msgstr ""

#: src/widgets/tools/tools.py:238 src/widgets/tools/tools.py:306
msgid "Source"
msgstr ""

#: src/widgets/tools/tools.py:276
msgid "Gets a list of food recipes by a specified category"
msgstr ""

#: src/widgets/tools/tools.py:333
msgid "Extracts an article from Wikipedia by it's title"
msgstr ""

#: src/widgets/tools/tools.py:375
msgid "Search for a term online using DuckDuckGo"
msgstr ""

#: src/widgets/tools/tools.py:393
msgid "Abstract Source"
msgstr ""

#: src/widgets/tools/tools.py:417
msgid "Official Website"
msgstr ""

#: src/widgets/tools/tools.py:468
msgid "Request to run a command using SSH to connect to the device"
msgstr ""

#: src/widgets/tools/tools.py:471
msgid "IP Address"
msgstr ""

#: src/widgets/tools/tools.py:476
msgid "Username"
msgstr ""

#: src/widgets/tools/tools.py:481
msgid "Network Port"
msgstr ""

#: src/widgets/tools/tools.py:498
msgid "Model Requested to Run Command"
msgstr ""

#: src/widgets/tools/tools.py:499
msgid "Command"
msgstr ""

#: src/widgets/tools/tools.py:501
msgid "Explanation"
msgstr ""

#: src/widgets/tools/tools.py:502
msgid "No explanation was provided"
msgstr ""

#: src/widgets/tools/tools.py:503
msgid "Make sure you understand what the command does before running it."
msgstr ""

#~ msgid "Save Conversation to Alpaca"
#~ msgstr "Сохранить беседу в Alpaca"

#~ msgid "Cannot open image"
#~ msgstr "Не удается открыть изображение"

#~ msgid "Remove Attachment?"
#~ msgstr "Удалить вложение?"

#~ msgid "Are you sure you want to remove attachment?"
#~ msgstr "Вы уверены, что хотите удалить вложение?"

#~ msgid "File preview dialog"
#~ msgstr "Диалоговое окно предварительного просмотра файла"

#~ msgid "Open With Default App"
#~ msgstr "Открыть с помощью приложения по умолчанию"

#~ msgid "An error occurred while extracting text from the website"
#~ msgstr "При извлечении текста с веб-сайта произошла ошибка"

#~ msgid "Message edited successfully"
#~ msgstr "Сообщение успешно изменено"

#~ msgid "Execute"
#~ msgstr "Выполнить"

#~ msgid "Missing image"
#~ msgstr "Изображение отсутствует"

#~ msgid "Compiling C++ script..."
#~ msgstr "Компиляция скрипта C++..."

#~ msgid "Running local web server"
#~ msgstr "Запуск локального веб-сервера"

#~ msgid "Clear Chat?"
#~ msgstr "Очистить чат?"

#~ msgid "Are you sure you want to clear the chat?"
#~ msgstr "Вы уверены, что хотите очистить чат?"

#~ msgid "Clear"
#~ msgstr "Очистить"

#~ msgid "Clear Chat"
#~ msgstr "Очистить Чат"

#~ msgid "Which network port will Ollama use"
#~ msgstr "Какой сетевой порт будет использовать Ollama?"

#~ msgid "General"
#~ msgstr "Общие"

#~ msgid "Bearer Token (Optional)"
#~ msgstr "Токен на предъявителя (необязательно)"

#~ msgid "Connect"
#~ msgstr "Подключить"

#~ msgid "Close Alpaca"
#~ msgstr "Закрыть Программу"

#~ msgid "Connection Error"
#~ msgstr "Ошибка Соединения"

#~ msgid "The remote instance has disconnected"
#~ msgstr "Удаленный экземпляр отключился"

#~ msgid ""
#~ "There was an error with the local Ollama instance, so it has been reset"
#~ msgstr ""
#~ "Произошла ошибка с локальным экземпляром Ollama, поэтому он был сброшен"

#~ msgid "Use Remote Connection to Ollama"
#~ msgstr "Использовать удаленное подключение к Ollama"

#~ msgid ""
#~ "The temperature of the model. Increasing the temperature will make the "
#~ "model answer more creatively. (Default: 0.8)"
#~ msgstr ""
#~ "Температура модели. При повышении температуры модель будет реагировать "
#~ "более творчески. (По умолчанию: 0,8)"

#~ msgid ""
#~ "Sets the random number seed to use for generation. Setting this to a "
#~ "specific number will make the model generate the same text for the same "
#~ "prompt. (Default: 0 (random))"
#~ msgstr ""
#~ "Задает начальное значение случайного числа, которое будет использоваться "
#~ "для генерации. Установка этого значения на определенное число заставит "
#~ "модель генерировать один и тот же текст для одного и того же запроса. (По "
#~ "умолчанию: 0 (случайный))"

#~ msgid "Keep Alive Time"
#~ msgstr "Время сохранения жизни"

#~ msgid ""
#~ "Controls how long the model will stay loaded into memory following the "
#~ "request in minutes (Default: 5)"
#~ msgstr ""
#~ "Определяет, как долго модель будет загружаться в память после запроса в "
#~ "минутах (по умолчанию: 5)."

#~ msgid "Ollama Instance"
#~ msgstr "Экземпляр Ollama"

#~ msgid "Ollama Overrides"
#~ msgstr "Переопределения Ollama"

#~ msgid ""
#~ "Manage the arguments used on Ollama, any changes on this page only "
#~ "applies to the integrated instance, the instance will restart if you make "
#~ "changes."
#~ msgstr ""
#~ "Управляйте аргументами, используемыми в Ollama, любые изменения на этой "
#~ "странице применимы только к интегрированному экземпляру, экземпляр будет "
#~ "перезапущен, если вы внесете изменения."

#~ msgid "Powered by Ollama"
#~ msgstr "При поддержке Ollama"

#~ msgid "Ollama Website"
#~ msgstr "Веб-сайт Ollama"

#~ msgid ""
#~ "Alpaca and its developers are not liable for any damages to devices or "
#~ "software resulting from the execution of code generated by an AI model. "
#~ "Please exercise caution and review the code carefully before running it."
#~ msgstr ""
#~ "Alpaca и ее разработчики не несут ответственности за любой ущерб, "
#~ "причиненный устройствам или программному обеспечению в результате "
#~ "выполнения кода, сгенерированного с помощью модели искусственного "
#~ "интеллекта. Пожалуйста, будьте осторожны и внимательно ознакомьтесь с "
#~ "кодом перед его запуском."

#~ msgid "From Existing Model"
#~ msgstr "Из существующей модели"

#~ msgid "image"
#~ msgstr "изображение"

#~ msgid "Select Model"
#~ msgstr "Выбор модели"

#~ msgid "This model will be used as the base for the new model"
#~ msgstr "Эта модель будет использована в качестве базовой для новой модели"

#~ msgid "Create Model"
#~ msgstr "Создать Модель"

#~ msgid ""
#~ "By downloading this model you accept the license agreement available on "
#~ "the model's website."
#~ msgstr ""
#~ "Загружая эту модель, вы принимаете лицензионное соглашение, доступное на "
#~ "веб-сайте модели."

#~ msgid "Create"
#~ msgstr "Создать"

#~ msgid "Delete Model?"
#~ msgstr "Удалить модель?"

#~ msgid "Model deleted successfully"
#~ msgstr "Модель успешно удалена"

#~ msgid "Task Complete"
#~ msgstr "Задача выполнена"

#~ msgid "Model '{}' pulled successfully."
#~ msgstr "Модель '{}' успешно извлечена."

#~ msgid "Pull Model Error"
#~ msgstr "Ошибка Извлечения Модели"

#~ msgid "Failed to pull model '{}' due to network error."
#~ msgstr "Не удалось извлечь модель '{}' из-за сетевой ошибки."

#~ msgid "Close application"
#~ msgstr "Закрыть приложение"

#~ msgid "Import chat"
#~ msgstr "Импорт чата"

#~ msgid "Clear chat"
#~ msgstr "Очистить чат"

#~ msgid "New chat"
#~ msgstr "Новый чат"

#~ msgid "Show shortcuts window"
#~ msgstr "Показать окно комбинаций клавиш"

#~ msgid "Editor"
#~ msgstr "Редактор"

#~ msgid "Image Recognition"
#~ msgstr "Распознавание изображений"

#~ msgid "This video is not available"
#~ msgstr "Это видео недоступно"

#~ msgid "Chat cannot be cleared while receiving a message"
#~ msgstr "Чат не может быть удален при получении сообщения"

#~ msgid "Create Chat?"
#~ msgstr "Создать чат?"

#~ msgid "Enter name for new chat"
#~ msgstr "Введите название для нового чата"

#~ msgid "Use local instance"
#~ msgstr "Использовать локальный экземпляр"

#~ msgid "An error occurred while creating the model"
#~ msgstr "При создании модели произошла ошибка"

#~ msgid "URL of Remote Instance"
#~ msgstr "URL удаленного экземпляра"

#~ msgid "Failed to connect to server"
#~ msgstr "Не удалось подключиться к серверу"

#~ msgid "Stop Creating '{}'"
#~ msgstr "Остановить создание '{}'"

#~ msgid "Google Gemma 2 is now available in 2 sizes, 9B and 27B."
#~ msgstr "Google Gemma 2 теперь доступен в двух размерах: 9B и 27B."

#~ msgid "Are you sure you want to stop pulling '{} ({})'?"
#~ msgstr "Вы уверены, что хотите прекратить извлечение '{} ({})'?"

#~ msgid "Try a different search"
#~ msgstr "Попробуйте другой поиск"

#~ msgid "Pulling in the background..."
#~ msgstr "Извлечение в фоновом режиме..."

#~ msgid "Featured Models"
#~ msgstr "Рекомендуемые модели"

#~ msgid "Built by Meta"
#~ msgstr "Построенный с помощью Meta"

#~ msgid "Built by Google DeepMind"
#~ msgstr "Создан Google DeepMind"

#~ msgid "Built by Microsoft"
#~ msgstr "Создан корпорацией Майкрософт"

#~ msgid "Multimodal AI with image recognition"
#~ msgstr ""
#~ "Мультимодальный искусственный интеллект с распознаванием изображений"

#~ msgid "Remove '{} ({})'"
#~ msgstr "Удалить '{} ({})'"

#~ msgid "Stop Pulling '{} ({})'"
#~ msgstr "Остановить извлечение '{} ({})'"

#~ msgid "Template"
#~ msgstr "Шаблон"

#~ msgid ""
#~ "Some models require a specific template. Please visit the model's website "
#~ "for more information if you're unsure."
#~ msgstr ""
#~ "Для некоторых моделей требуется специальный шаблон. Если вы не уверены, "
#~ "пожалуйста, посетите веб-сайт модели для получения дополнительной "
#~ "информации."

#~ msgid "From GGUF File (Experimental)"
#~ msgstr "Из файла GGUF (экспериментальный)"

#~ msgid "Open with Default App"
#~ msgstr "Открыть с помощью приложения по умолчанию"

#~ msgid ""
#~ "Alpaca works locally on your device, to start chatting you'll need an AI "
#~ "model, you can either pull models from this list or the 'Manage Models' "
#~ "menu later."
#~ msgstr ""
#~ "Alpaca работает локально на вашем устройстве, чтобы начать общение в "
#~ "чате, вам понадобится модель с искусственным интеллектом, вы можете "
#~ "выбрать модели из этого списка или из меню \"Управление моделями\" позже."
